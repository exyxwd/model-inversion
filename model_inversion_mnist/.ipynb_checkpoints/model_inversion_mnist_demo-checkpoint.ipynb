{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8f4380",
   "metadata": {},
   "source": [
    "# üß† Model Inversion on MNIST using Label-only Attack\n",
    "This notebook demonstrates how to reconstruct images using model inversion attacks with only label information, following the structure of the paper: **'Label-only Model Inversion Attack: The Attack that Requires the Least'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18a5cc",
   "metadata": {},
   "source": [
    "## üì• Step 1: Setup and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccae809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (0.21.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (3.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3393279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfad26eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14233691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipykernel in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (1.8.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (8.28.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (308)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec torch_env in C:\\Users\\USER\\AppData\\Roaming\\jupyter\\kernels\\torch_env\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install ipykernel\n",
    "!python -m ipykernel install --user --name torch_env --display-name \"Python (with torch)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d863b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec torch_env in C:\\Users\\USER\\AppData\\Roaming\\jupyter\\kernels\\torch_env\n"
     ]
    }
   ],
   "source": [
    "!python -m ipykernel install --user --name=torch_env --display-name \"Python (with torch)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19bedffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed30f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch.optim as optim\n",
    "from utils import compute_error_rate, add_gaussian_noise # ƒê·∫£m b·∫£o import ƒë·ªß\n",
    "import torch.nn as nn # Import nn\n",
    "\n",
    "\n",
    "# Th√™m th∆∞ m·ª•c hi·ªán t·∫°i v√†o sys.path ƒë·ªÉ import ƒë∆∞·ª£c c√°c file .py b√™n c·∫°nh\n",
    "sys.path.append(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8647f3",
   "metadata": {},
   "source": [
    "## üìÅ Step 2: Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157ac3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000, Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "from data_loader import load_mnist_data\n",
    "train_set, test_set = load_mnist_data()\n",
    "print(f\"Training samples: {len(train_set)}, Test samples: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b5dc2",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 3: Build a Dummy Target Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b009b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Target CNN...\n",
      "Epoch 1, Target Model Loss: 0.1196, Accuracy: 96.43%\n",
      "Epoch 2, Target Model Loss: 0.0388, Accuracy: 98.77%\n",
      "Epoch 3, Target Model Loss: 0.0295, Accuracy: 99.07%\n",
      "Epoch 4, Target Model Loss: 0.0224, Accuracy: 99.25%\n",
      "Epoch 5, Target Model Loss: 0.0170, Accuracy: 99.44%\n",
      "Target CNN training finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TargetCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1152, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Thay th·∫ø n·ªôi dung Cell 9 ---\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset # Th√™m Subset n·∫øu c·∫ßn\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a TargetCNN\n",
    "class TargetCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        # T√≠nh to√°n k√≠ch th∆∞·ªõc input cho l·ªõp Linear ƒë·∫ßu ti√™n c·∫©n th·∫≠n\n",
    "        # V√≠ d·ª• MNIST 28x28 -> qua 3 MaxPool2d -> 28/2/2/2 = 3.5 -> l√†m tr√≤n xu·ªëng 3\n",
    "        # K√≠ch th∆∞·ªõc cu·ªëi c√πng l√† 128 k√™nh * 3 * 3\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*3*3, 256), nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán TargetCNN\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "target_model = TargetCNN().to(device) # S·ª≠ d·ª•ng CNN\n",
    "\n",
    "# Chu·∫©n b·ªã DataLoader ƒë·ªÉ train target model (v√≠ d·ª• d√πng to√†n b·ªô train_set)\n",
    "# ƒê·∫£m b·∫£o b·∫°n ƒë√£ load train_set ·ªü Cell 8\n",
    "loader_target_train = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "\n",
    "# Hu·∫•n luy·ªán target_model\n",
    "optimizer = optim.Adam(target_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5 # S·ªë epochs v√≠ d·ª• (c√≥ th·ªÉ c·∫ßn nhi·ªÅu h∆°n)\n",
    "print(\"Training Target CNN...\")\n",
    "for epoch in range(epochs):\n",
    "    target_model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for imgs, labels in loader_target_train:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = target_model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total_train\n",
    "    accuracy = 100 * correct_train / total_train\n",
    "    print(f\"Epoch {epoch+1}, Target Model Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Target CNN training finished.\")\n",
    "target_model.eval() # Chuy·ªÉn sang ch·∫ø ƒë·ªô ƒë√°nh gi√°\n",
    "# --- K·∫øt th√∫c thay th·∫ø Cell 9 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebddb44",
   "metadata": {},
   "source": [
    "## üß™ Step 4: Prepare Sample Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d708590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [test_set[i] for i in range(10)]\n",
    "images = torch.stack([img for img, _ in samples])\n",
    "labels = torch.tensor([label for _, label in samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce506410",
   "metadata": {},
   "source": [
    "## üß© Step 5: Generate Confidence Vectors from 4 Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ff27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shadow Model...\n",
      "  Shadow Epoch [20/100], Loss: 0.1895\n",
      "  Shadow Epoch [40/100], Loss: 0.1525\n",
      "  Shadow Epoch [60/100], Loss: 0.1219\n",
      "  Shadow Epoch [80/100], Loss: 0.1057\n",
      "  Shadow Epoch [100/100], Loss: 0.0890\n",
      "Shadow Model training finished.\n",
      "Processing label_only...\n",
      "Calculated mu for label-only: 0.7800\n",
      "label_only: vectors torch.Size([10, 10]), targets torch.Size([10, 1, 28, 28])\n",
      "Processing other methods...\n",
      " Processing vector_based...\n",
      " vector_based: vectors torch.Size([10, 10]), targets torch.Size([10, 1, 28, 28])\n",
      " Processing score_based...\n",
      " score_based: vectors torch.Size([10, 10]), targets torch.Size([10, 1, 28, 28])\n",
      " Processing one_hot...\n",
      " one_hot: vectors torch.Size([10, 10]), targets torch.Size([10, 1, 28, 28])\n",
      "Confidence vector generation finished for all methods.\n",
      "\n",
      "--- Checking Generated Vectors (First Sample) ---\n",
      "Sample Label: 7\n",
      "\n",
      "Method: label_only\n",
      "tensor([0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.0000, 0.1110,\n",
      "        0.1110])\n",
      "\n",
      "Method: vector_based\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "\n",
      "Method: score_based\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "\n",
      "Method: one_hot\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Computer Science\\ELTE's MSc\\Data Security\\model_inversion_mnist - Copy - Good lastesr version\\model_inversion_mnist\\attacks\\label_only_attack.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  phi_inv_mu_tensor = torch.tensor(phi_inv_mu, dtype=torch.float32, device='cpu') # Ensure tensor\n"
     ]
    }
   ],
   "source": [
    "# --- Thay th·∫ø n·ªôi dung Cell 11 ---\n",
    "from attacks.label_only_attack import train_shadow_model # Gi·ªØ l·∫°i import\n",
    "from utils import add_gaussian_noise, compute_error_rate # ƒê·∫£m b·∫£o import ƒë·ªß\n",
    "from phase1_vector_recovery import generate_confidence_vectors # Gi·ªØ l·∫°i import\n",
    "\n",
    "# 1. Chu·∫©n b·ªã d·ªØ li·ªáu cho Shadow Model v√† t√≠nh mu\n",
    "n_aux = 1000 # S·ªë l∆∞·ª£ng m·∫´u ph·ª• tr·ª£ d∆∞∆°ng\n",
    "n_neg = 100 # S·ªë l∆∞·ª£ng m·∫´u ph·ª• tr·ª£ √¢m (v√≠ d·ª•)\n",
    "aux_indices = list(range(n_aux))\n",
    "# ƒê·∫£m b·∫£o n_neg ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a (v√≠ d·ª•: n_neg = 100 ho·∫∑c n_neg = n_aux)\n",
    "neg_indices = list(range(n_aux, n_aux + n_neg)) # B·∫Øt ƒë·∫ßu ngay sau aux_indices\n",
    "\n",
    "# L·∫•y aux_images v√† aux_labels (positive samples cho shadow & t√≠nh mu)\n",
    "aux_images_list = []\n",
    "aux_labels_list = []\n",
    "for i in aux_indices:\n",
    "    img, label = train_set[i]\n",
    "    aux_images_list.append(img)\n",
    "    aux_labels_list.append(label)\n",
    "aux_images = torch.stack(aux_images_list)\n",
    "aux_labels = torch.tensor(aux_labels_list) # Nh√£n g·ªëc c·ªßa aux_images\n",
    "\n",
    "# L·∫•y d_neg (negative samples cho shadow)\n",
    "d_neg = torch.stack([train_set[i][0] for i in neg_indices])\n",
    "\n",
    "# 2. Hu·∫•n luy·ªán Shadow Model (tr√™n CPU)\n",
    "# H√†m train_shadow_model ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·ªÉ nh·∫≠n D_aux, D_neg\n",
    "shadow_model = train_shadow_model(aux_images, d_neg, epochs=100) # C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh epochs\n",
    "\n",
    "# 3. T·∫°o Confidence Vectors\n",
    "vectors_by_method = {}\n",
    "targets_by_method = {} # Th√™m dict n√†y n·∫øu b·∫°n mu·ªën l∆∞u target images t∆∞∆°ng ·ª©ng\n",
    "\n",
    "# Chuy·ªÉn d·ªØ li·ªáu test (images, labels t·ª´ Cell 10) v√† models sang device\n",
    "images = images.to(device) # images, labels l√† 10 sample test ban ƒë·∫ßu\n",
    "labels = labels.cpu() # Gi·ªØ labels tr√™n CPU v√¨ d√πng .item()\n",
    "target_model.to(device).eval()\n",
    "aux_images = aux_images.to(device) # aux_images c≈©ng c·∫ßn tr√™n device ƒë·ªÉ t√≠nh mu\n",
    "aux_labels = aux_labels.to(device) # aux_labels t∆∞∆°ng ·ª©ng\n",
    "\n",
    "# -- X·ª≠ l√Ω ri√™ng cho label_only --\n",
    "print(\"Processing label_only...\")\n",
    "sigma = 0.3 # Gi√° tr·ªã sigma\n",
    "noisy_aux = add_gaussian_noise(aux_images, sigma=sigma).to(device)\n",
    "mu = compute_error_rate(target_model, noisy_aux, aux_labels, device)\n",
    "print(f\"Calculated mu for label-only: {mu:.4f}\")\n",
    "\n",
    "vectors_label_only, targets_label_only = generate_confidence_vectors(\n",
    "    images=images.cpu(),    # Truy·ªÅn d·ªØ li·ªáu test g·ªëc (tr√™n CPU cho h√†m n√†y)\n",
    "    labels=labels.cpu(),    # Nh√£n test g·ªëc (tr√™n CPU)\n",
    "    target_model=target_model, # Model target\n",
    "    method=\"label_only\",\n",
    "    shadow_model=shadow_model, # Model shadow ƒë√£ train\n",
    "    mu=mu,                 # mu ƒë√£ t√≠nh\n",
    "    sigma=sigma,           # sigma\n",
    "    num_classes=10,\n",
    "    device=device          # device ƒë·ªÉ target_model ch·∫°y n·∫øu c·∫ßn b√™n trong h√†m\n",
    ")\n",
    "vectors_by_method[\"label_only\"] = vectors_label_only\n",
    "targets_by_method[\"label_only\"] = targets_label_only # L∆∞u ·∫£nh g·ªëc l√†m target\n",
    "print(f\"label_only: vectors {vectors_label_only.shape}, targets {targets_label_only.shape}\")\n",
    "\n",
    "\n",
    "# -- X·ª≠ l√Ω c√°c ph∆∞∆°ng th·ª©c c√≤n l·∫°i --\n",
    "other_methods = [\"vector_based\", \"score_based\", \"one_hot\"]\n",
    "print(\"Processing other methods...\")\n",
    "for method in other_methods:\n",
    "    print(f\" Processing {method}...\")\n",
    "    vectors, targets = generate_confidence_vectors(\n",
    "        images=images.cpu(),\n",
    "        labels=labels.cpu(),\n",
    "        target_model=target_model,\n",
    "        method=method,\n",
    "        # Kh√¥ng c·∫ßn shadow_model, mu, sigma\n",
    "        num_classes=10,\n",
    "        device=device\n",
    "    )\n",
    "    vectors_by_method[method] = vectors\n",
    "    targets_by_method[method] = targets # L∆∞u ·∫£nh g·ªëc l√†m target\n",
    "    print(f\" {method}: vectors {vectors.shape}, targets {targets.shape}\")\n",
    "\n",
    "print(\"Confidence vector generation finished for all methods.\")\n",
    "# --- K·∫øt th√∫c thay th·∫ø Cell 11 ---\n",
    "\n",
    "\n",
    "# Th√™m v√†o cu·ªëi Cell 11\n",
    "print(\"\\n--- Checking Generated Vectors (First Sample) ---\")\n",
    "target_model.to(device) # ƒê·∫£m b·∫£o model tr√™n device\n",
    "sample_image_cpu = images[0].cpu() # L·∫•y ·∫£nh ƒë·∫ßu ti√™n (CPU)\n",
    "sample_image_device = images[0].to(device) # L·∫•y ·∫£nh ƒë·∫ßu ti√™n (Device)\n",
    "sample_label = labels[0].item() # L·∫•y nh√£n ƒë·∫ßu ti√™n\n",
    "\n",
    "print(f\"Sample Label: {sample_label}\")\n",
    "\n",
    "# Label-only\n",
    "print(\"\\nMethod: label_only\")\n",
    "# L·∫•y vector ƒë√£ t√≠nh tr∆∞·ªõc ƒë√≥\n",
    "print(torch.round(vectors_by_method[\"label_only\"][0] * 1000) / 1000) # L√†m tr√≤n 3 ch·ªØ s·ªë\n",
    "\n",
    "# Vector-based (T√≠nh l·∫°i cho m·∫´u ƒë·∫ßu ti√™n)\n",
    "print(\"\\nMethod: vector_based\")\n",
    "with torch.no_grad():\n",
    "    vec_vb = torch.softmax(target_model(sample_image_device.unsqueeze(0)), dim=1).squeeze()\n",
    "print(torch.round(vec_vb.cpu() * 1000) / 1000)\n",
    "\n",
    "# Score-based (T√≠nh l·∫°i cho m·∫´u ƒë·∫ßu ti√™n)\n",
    "print(\"\\nMethod: score_based\")\n",
    "with torch.no_grad():\n",
    "    prob_sb = torch.softmax(target_model(sample_image_device.unsqueeze(0)), dim=1).squeeze()\n",
    "    max_idx_sb = torch.argmax(prob_sb)\n",
    "    vec_sb = torch.zeros_like(prob_sb)\n",
    "    vec_sb[max_idx_sb] = prob_sb[max_idx_sb]\n",
    "print(torch.round(vec_sb.cpu() * 1000) / 1000)\n",
    "\n",
    "# One-hot (T√≠nh l·∫°i cho m·∫´u ƒë·∫ßu ti√™n)\n",
    "print(\"\\nMethod: one_hot\")\n",
    "with torch.no_grad():\n",
    "     pred_oh = torch.argmax(target_model(sample_image_device.unsqueeze(0)), dim=1).item()\n",
    "vec_oh = torch.zeros(10)\n",
    "vec_oh[pred_oh] = 1.0\n",
    "print(torch.round(vec_oh.cpu() * 1000) / 1000)\n",
    "\n",
    "print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1750ce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data for Attack Models...\n",
      "Using sigma=0.3, mu=0.78 from previous cell for label_only training data generation.\n",
      " Generating attack training data...\n",
      " Stacking tensors...\n",
      " Method label_only: Created 1000 training pairs.\n",
      " Method vector_based: Created 1000 training pairs.\n",
      " Method score_based: Created 1000 training pairs.\n",
      " Method one_hot: Created 1000 training pairs.\n",
      "Finished generating training data for Attack Models.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL M·ªöI: Chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán cho Attack Models ---\n",
    "from torch.utils.data import TensorDataset, DataLoader # Th√™m import n·∫øu ch∆∞a c√≥ ·ªü ƒë·∫ßu notebook\n",
    "from attacks.label_only_attack import recover_confidence_vector # Import h√†m n√†y\n",
    "\n",
    "print(\"Generating training data for Attack Models...\")\n",
    "\n",
    "# D·ªØ li·ªáu ph·ª• tr·ª£ b·∫°n d√πng ƒë·ªÉ train shadow model v√† t√≠nh mu\n",
    "# aux_images, aux_labels (ƒë√£ c√≥ t·ª´ Cell 11)\n",
    "# Gi·∫£ ƒë·ªãnh aux_images, aux_labels ƒëang ·ªü tr√™n CPU sau khi train shadow_model\n",
    "# N·∫øu kh√¥ng, chuy·ªÉn v·ªÅ CPU: aux_images = aux_images.cpu(); aux_labels = aux_labels.cpu()\n",
    "\n",
    "attack_train_data = {\n",
    "    \"label_only\": {\"vectors\": [], \"images\": []},\n",
    "    \"vector_based\": {\"vectors\": [], \"images\": []},\n",
    "    \"score_based\": {\"vectors\": [], \"images\": []},\n",
    "    \"one_hot\": {\"vectors\": []} # One-hot kh√¥ng c·∫ßn ·∫£nh target v√¨ vector ch·ªâ ph·ª• thu·ªôc label d·ª± ƒëo√°n\n",
    "                               # Nh∆∞ng ƒë·ªÉ nh·∫•t qu√°n, ta v·∫´n th√™m ·∫£nh target\n",
    "}\n",
    "# Ch·ªânh s·ª≠a: Th√™m images v√†o one_hot ƒë·ªÉ c·∫•u tr√∫c nh·∫•t qu√°n\n",
    "attack_train_data[\"one_hot\"][\"images\"] = []\n",
    "\n",
    "\n",
    "# Device v√† models (ƒë·∫£m b·∫£o ch√∫ng ·ªü tr·∫°ng th√°i v√† device ph√π h·ª£p)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "target_model.to(device).eval()\n",
    "# shadow_model ƒë√£ ƒë∆∞·ª£c train v√† tr·∫£ v·ªÅ CPU trong h√†m train_shadow_model\n",
    "shadow_model.cpu().eval()\n",
    "\n",
    "# L·∫•y c√°c gi√° tr·ªã mu v√† sigma ƒë√£ d√πng/t√≠nh ·ªü Cell 11 cho label_only\n",
    "# B·∫°n c·∫ßn ƒë·∫£m b·∫£o bi·∫øn sigma v√† mu n√†y t·ªìn t·∫°i t·ª´ Cell 11\n",
    "# sigma_for_label_only = 0.3 # V√≠ d·ª• l·∫•y t·ª´ l·∫ßn ch·∫°y tr∆∞·ªõc\n",
    "# mu_for_label_only = 0.73    # V√≠ d·ª• l·∫•y t·ª´ l·∫ßn ch·∫°y tr∆∞·ªõc\n",
    "# HO·∫∂C T√çNH L·∫†I ·ªû ƒê√ÇY n·∫øu c·∫ßn\n",
    "try:\n",
    "    # Gi·∫£ s·ª≠ sigma v√† mu ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a ·ªü cell tr∆∞·ªõc\n",
    "    sigma_for_label_only = sigma\n",
    "    mu_for_label_only = mu\n",
    "    print(f\"Using sigma={sigma_for_label_only}, mu={mu_for_label_only} from previous cell for label_only training data generation.\")\n",
    "except NameError:\n",
    "    print(\"Error: sigma and mu not defined from previous cell. Please run Cell 11 again.\")\n",
    "    # Ho·∫∑c ƒë·∫∑t gi√° tr·ªã m·∫∑c ƒë·ªãnh/t√≠nh l·∫°i ·ªü ƒë√¢y n·∫øu logic cho ph√©p\n",
    "    # V√≠ d·ª• t√≠nh l·∫°i (c·∫ßn aux_images, aux_labels tr√™n device):\n",
    "    # sigma_for_label_only = 0.3\n",
    "    # noisy_aux_temp = add_gaussian_noise(aux_images.to(device), sigma=sigma_for_label_only)\n",
    "    # mu_for_label_only = compute_error_rate(target_model, noisy_aux_temp, aux_labels.to(device), device)\n",
    "    # print(f\"Recalculated sigma={sigma_for_label_only}, mu={mu_for_label_only}\")\n",
    "\n",
    "\n",
    "# --- T·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán ---\n",
    "print(\" Generating attack training data...\")\n",
    "\n",
    "# S·ª≠ d·ª•ng DataLoader ƒë·ªÉ x·ª≠ l√Ω hi·ªáu qu·∫£ aux_images\n",
    "# T·∫°o dataset t·ª´ aux_images (CPU) v√† aux_labels (CPU)\n",
    "temp_aux_dataset = TensorDataset(aux_images.cpu(), aux_labels.cpu())\n",
    "temp_aux_loader = DataLoader(temp_aux_dataset, batch_size=128) # X·ª≠ l√Ω theo batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_batch_cpu, label_batch_cpu in temp_aux_loader:\n",
    "        # Chuy·ªÉn batch l√™n device ƒë·ªÉ ƒë∆∞a v√†o target_model\n",
    "        img_batch_device = img_batch_cpu.to(device)\n",
    "        softmax_output = torch.softmax(target_model(img_batch_device), dim=1)\n",
    "\n",
    "        for i in range(len(img_batch_cpu)):\n",
    "            img_orig = img_batch_cpu[i]    # ·∫¢nh g·ªëc (CPU)\n",
    "            label_orig = label_batch_cpu[i].item() # Nh√£n g·ªëc (int)\n",
    "\n",
    "            # --- Label-only ---\n",
    "            vec_lo = recover_confidence_vector(\n",
    "                shadow_model, mu_for_label_only, label_orig,\n",
    "                num_classes=10, sigma=sigma_for_label_only\n",
    "            )\n",
    "            attack_train_data[\"label_only\"][\"vectors\"].append(vec_lo)\n",
    "            attack_train_data[\"label_only\"][\"images\"].append(img_orig)\n",
    "\n",
    "            # --- Vector-based ---\n",
    "            vec_vb = softmax_output[i].cpu() # Vector t·ª´ target model (chuy·ªÉn v·ªÅ CPU)\n",
    "            attack_train_data[\"vector_based\"][\"vectors\"].append(vec_vb)\n",
    "            attack_train_data[\"vector_based\"][\"images\"].append(img_orig)\n",
    "\n",
    "            # --- Score-based ---\n",
    "            prob_sb = vec_vb\n",
    "            max_idx_sb = torch.argmax(prob_sb)\n",
    "            vec_sb = torch.zeros_like(prob_sb)\n",
    "            if 0 <= max_idx_sb < len(vec_sb): # Check index bounds\n",
    "                 vec_sb[max_idx_sb] = prob_sb[max_idx_sb]\n",
    "            attack_train_data[\"score_based\"][\"vectors\"].append(vec_sb)\n",
    "            attack_train_data[\"score_based\"][\"images\"].append(img_orig)\n",
    "\n",
    "            # --- One-hot ---\n",
    "            pred_oh = torch.argmax(prob_sb).item() # L·∫•y d·ª± ƒëo√°n t·ª´ softmax\n",
    "            vec_oh = torch.zeros_like(prob_sb)\n",
    "            if 0 <= pred_oh < len(vec_oh): # Check index bounds\n",
    "                 vec_oh[pred_oh] = 1.0\n",
    "            attack_train_data[\"one_hot\"][\"vectors\"].append(vec_oh)\n",
    "            attack_train_data[\"one_hot\"][\"images\"].append(img_orig) # Th√™m ·∫£nh target\n",
    "\n",
    "# Chuy·ªÉn list th√†nh Tensor\n",
    "print(\" Stacking tensors...\")\n",
    "methods = [\"label_only\", \"vector_based\", \"score_based\", \"one_hot\"]\n",
    "for method in methods:\n",
    "    if attack_train_data[method][\"vectors\"]:\n",
    "        attack_train_data[method][\"vectors\"] = torch.stack(attack_train_data[method][\"vectors\"])\n",
    "        attack_train_data[method][\"images\"] = torch.stack(attack_train_data[method][\"images\"])\n",
    "        print(f\" Method {method}: Created {len(attack_train_data[method]['vectors'])} training pairs.\")\n",
    "    else:\n",
    "        print(f\" Method {method}: No training data generated.\")\n",
    "\n",
    "print(\"Finished generating training data for Attack Models.\")\n",
    "# --- K·∫øt th√∫c CELL M·ªöI ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e093d",
   "metadata": {},
   "source": [
    "## üß† Step 6: Train Attack Model to Reconstruct Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad8fad2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Attack Models on cpu...\n",
      "\n",
      "Training attack model for: label_only\n",
      "  Training with 1000 samples...\n",
      " Training Attack Model (2000 epochs, lr=5e-05)...\n",
      "  Attack Epoch [50/2000], Average Loss: 0.205289\n",
      "  Attack Epoch [100/2000], Average Loss: 0.175248\n",
      "  Attack Epoch [150/2000], Average Loss: 0.140724\n",
      "  Attack Epoch [200/2000], Average Loss: 0.134202\n",
      "  Attack Epoch [250/2000], Average Loss: 0.101547\n",
      "  Attack Epoch [300/2000], Average Loss: 0.099778\n",
      "  Attack Epoch [350/2000], Average Loss: 0.099110\n",
      "  Attack Epoch [400/2000], Average Loss: 0.098797\n",
      "  Attack Epoch [450/2000], Average Loss: 0.098684\n",
      "  Attack Epoch [500/2000], Average Loss: 0.098588\n",
      "  Attack Epoch [550/2000], Average Loss: 0.098562\n",
      "  Attack Epoch [600/2000], Average Loss: 0.098577\n",
      "  Attack Epoch [650/2000], Average Loss: 0.098559\n",
      "  Attack Epoch [700/2000], Average Loss: 0.098441\n",
      "  Attack Epoch [750/2000], Average Loss: 0.098242\n",
      "  Attack Epoch [800/2000], Average Loss: 0.098335\n",
      "  Attack Epoch [850/2000], Average Loss: 0.098514\n",
      "  Attack Epoch [900/2000], Average Loss: 0.098339\n",
      "  Attack Epoch [950/2000], Average Loss: 0.098252\n",
      "  Attack Epoch [1000/2000], Average Loss: 0.098344\n",
      "  Attack Epoch [1050/2000], Average Loss: 0.098267\n",
      "  Attack Epoch [1100/2000], Average Loss: 0.098265\n",
      "  Attack Epoch [1150/2000], Average Loss: 0.098227\n",
      "  Attack Epoch [1200/2000], Average Loss: 0.098317\n",
      "  Attack Epoch [1250/2000], Average Loss: 0.098330\n",
      "  Attack Epoch [1300/2000], Average Loss: 0.098276\n",
      "  Attack Epoch [1350/2000], Average Loss: 0.098259\n",
      "  Attack Epoch [1400/2000], Average Loss: 0.098236\n",
      "  Attack Epoch [1450/2000], Average Loss: 0.098219\n",
      "  Attack Epoch [1500/2000], Average Loss: 0.098163\n",
      "  Attack Epoch [1550/2000], Average Loss: 0.098260\n",
      "  Attack Epoch [1600/2000], Average Loss: 0.098241\n",
      "  Attack Epoch [1650/2000], Average Loss: 0.098216\n",
      "  Attack Epoch [1700/2000], Average Loss: 0.098121\n",
      "  Attack Epoch [1750/2000], Average Loss: 0.098172\n",
      "  Attack Epoch [1800/2000], Average Loss: 0.098169\n",
      "  Attack Epoch [1850/2000], Average Loss: 0.098049\n",
      "  Attack Epoch [1900/2000], Average Loss: 0.098164\n",
      "  Attack Epoch [1950/2000], Average Loss: 0.098146\n",
      "  Attack Epoch [2000/2000], Average Loss: 0.098185\n",
      "  Final Attack Model Average Loss: 0.098185\n",
      "\n",
      "Training attack model for: vector_based\n",
      "  Training with 1000 samples...\n",
      " Training Attack Model (2000 epochs, lr=5e-05)...\n",
      "  Attack Epoch [50/2000], Average Loss: 0.218097\n",
      "  Attack Epoch [100/2000], Average Loss: 0.163566\n",
      "  Attack Epoch [150/2000], Average Loss: 0.139488\n",
      "  Attack Epoch [200/2000], Average Loss: 0.104036\n",
      "  Attack Epoch [250/2000], Average Loss: 0.100899\n",
      "  Attack Epoch [300/2000], Average Loss: 0.099464\n",
      "  Attack Epoch [350/2000], Average Loss: 0.099009\n",
      "  Attack Epoch [400/2000], Average Loss: 0.098633\n",
      "  Attack Epoch [450/2000], Average Loss: 0.098543\n",
      "  Attack Epoch [500/2000], Average Loss: 0.098243\n",
      "  Attack Epoch [550/2000], Average Loss: 0.098271\n",
      "  Attack Epoch [600/2000], Average Loss: 0.098034\n",
      "  Attack Epoch [650/2000], Average Loss: 0.098033\n",
      "  Attack Epoch [700/2000], Average Loss: 0.098155\n",
      "  Attack Epoch [750/2000], Average Loss: 0.097861\n",
      "  Attack Epoch [800/2000], Average Loss: 0.098025\n",
      "  Attack Epoch [850/2000], Average Loss: 0.097872\n",
      "  Attack Epoch [900/2000], Average Loss: 0.097898\n",
      "  Attack Epoch [950/2000], Average Loss: 0.097851\n",
      "  Attack Epoch [1000/2000], Average Loss: 0.097811\n",
      "  Attack Epoch [1050/2000], Average Loss: 0.097696\n",
      "  Attack Epoch [1100/2000], Average Loss: 0.097679\n",
      "  Attack Epoch [1150/2000], Average Loss: 0.097623\n",
      "  Attack Epoch [1200/2000], Average Loss: 0.097664\n",
      "  Attack Epoch [1250/2000], Average Loss: 0.097678\n",
      "  Attack Epoch [1300/2000], Average Loss: 0.097796\n",
      "  Attack Epoch [1350/2000], Average Loss: 0.097582\n",
      "  Attack Epoch [1400/2000], Average Loss: 0.097573\n",
      "  Attack Epoch [1450/2000], Average Loss: 0.097542\n",
      "  Attack Epoch [1500/2000], Average Loss: 0.097540\n",
      "  Attack Epoch [1550/2000], Average Loss: 0.097476\n",
      "  Attack Epoch [1600/2000], Average Loss: 0.097581\n",
      "  Attack Epoch [1650/2000], Average Loss: 0.097441\n",
      "  Attack Epoch [1700/2000], Average Loss: 0.097463\n",
      "  Attack Epoch [1750/2000], Average Loss: 0.097515\n",
      "  Attack Epoch [1800/2000], Average Loss: 0.097601\n",
      "  Attack Epoch [1850/2000], Average Loss: 0.097401\n",
      "  Attack Epoch [1900/2000], Average Loss: 0.097481\n",
      "  Attack Epoch [1950/2000], Average Loss: 0.097462\n",
      "  Attack Epoch [2000/2000], Average Loss: 0.097457\n",
      "  Final Attack Model Average Loss: 0.097457\n",
      "\n",
      "Training attack model for: score_based\n",
      "  Training with 1000 samples...\n",
      " Training Attack Model (2000 epochs, lr=5e-05)...\n",
      "  Attack Epoch [50/2000], Average Loss: 0.245818\n",
      "  Attack Epoch [100/2000], Average Loss: 0.194938\n",
      "  Attack Epoch [150/2000], Average Loss: 0.139533\n",
      "  Attack Epoch [200/2000], Average Loss: 0.134134\n",
      "  Attack Epoch [250/2000], Average Loss: 0.128326\n",
      "  Attack Epoch [300/2000], Average Loss: 0.100184\n",
      "  Attack Epoch [350/2000], Average Loss: 0.099191\n",
      "  Attack Epoch [400/2000], Average Loss: 0.098790\n",
      "  Attack Epoch [450/2000], Average Loss: 0.098512\n",
      "  Attack Epoch [500/2000], Average Loss: 0.098457\n",
      "  Attack Epoch [550/2000], Average Loss: 0.098359\n",
      "  Attack Epoch [600/2000], Average Loss: 0.098096\n",
      "  Attack Epoch [650/2000], Average Loss: 0.098256\n",
      "  Attack Epoch [700/2000], Average Loss: 0.098139\n",
      "  Attack Epoch [750/2000], Average Loss: 0.098172\n",
      "  Attack Epoch [800/2000], Average Loss: 0.098098\n",
      "  Attack Epoch [850/2000], Average Loss: 0.098032\n",
      "  Attack Epoch [900/2000], Average Loss: 0.097935\n",
      "  Attack Epoch [950/2000], Average Loss: 0.097945\n",
      "  Attack Epoch [1000/2000], Average Loss: 0.097846\n",
      "  Attack Epoch [1050/2000], Average Loss: 0.097966\n",
      "  Attack Epoch [1100/2000], Average Loss: 0.097869\n",
      "  Attack Epoch [1150/2000], Average Loss: 0.097807\n",
      "  Attack Epoch [1200/2000], Average Loss: 0.097876\n",
      "  Attack Epoch [1250/2000], Average Loss: 0.097846\n",
      "  Attack Epoch [1300/2000], Average Loss: 0.097894\n",
      "  Attack Epoch [1350/2000], Average Loss: 0.097781\n",
      "  Attack Epoch [1400/2000], Average Loss: 0.097711\n",
      "  Attack Epoch [1450/2000], Average Loss: 0.097785\n",
      "  Attack Epoch [1500/2000], Average Loss: 0.097784\n",
      "  Attack Epoch [1550/2000], Average Loss: 0.097770\n",
      "  Attack Epoch [1600/2000], Average Loss: 0.097746\n",
      "  Attack Epoch [1650/2000], Average Loss: 0.097776\n",
      "  Attack Epoch [1700/2000], Average Loss: 0.097666\n",
      "  Attack Epoch [1750/2000], Average Loss: 0.097667\n",
      "  Attack Epoch [1800/2000], Average Loss: 0.097699\n",
      "  Attack Epoch [1850/2000], Average Loss: 0.097602\n",
      "  Attack Epoch [1900/2000], Average Loss: 0.097658\n",
      "  Attack Epoch [1950/2000], Average Loss: 0.097658\n",
      "  Attack Epoch [2000/2000], Average Loss: 0.097656\n",
      "  Final Attack Model Average Loss: 0.097656\n",
      "\n",
      "Training attack model for: one_hot\n",
      "  Training with 1000 samples...\n",
      " Training Attack Model (2000 epochs, lr=5e-05)...\n",
      "  Attack Epoch [50/2000], Average Loss: 0.153415\n",
      "  Attack Epoch [100/2000], Average Loss: 0.121267\n",
      "  Attack Epoch [150/2000], Average Loss: 0.109357\n",
      "  Attack Epoch [200/2000], Average Loss: 0.103960\n",
      "  Attack Epoch [250/2000], Average Loss: 0.101004\n",
      "  Attack Epoch [300/2000], Average Loss: 0.099667\n",
      "  Attack Epoch [350/2000], Average Loss: 0.098951\n",
      "  Attack Epoch [400/2000], Average Loss: 0.098781\n",
      "  Attack Epoch [450/2000], Average Loss: 0.098549\n",
      "  Attack Epoch [500/2000], Average Loss: 0.098666\n",
      "  Attack Epoch [550/2000], Average Loss: 0.098543\n",
      "  Attack Epoch [600/2000], Average Loss: 0.098444\n",
      "  Attack Epoch [650/2000], Average Loss: 0.098316\n",
      "  Attack Epoch [700/2000], Average Loss: 0.098319\n",
      "  Attack Epoch [750/2000], Average Loss: 0.098343\n",
      "  Attack Epoch [800/2000], Average Loss: 0.098298\n",
      "  Attack Epoch [850/2000], Average Loss: 0.098314\n",
      "  Attack Epoch [900/2000], Average Loss: 0.098259\n",
      "  Attack Epoch [950/2000], Average Loss: 0.098236\n",
      "  Attack Epoch [1000/2000], Average Loss: 0.098189\n",
      "  Attack Epoch [1050/2000], Average Loss: 0.098227\n",
      "  Attack Epoch [1100/2000], Average Loss: 0.098289\n",
      "  Attack Epoch [1150/2000], Average Loss: 0.098117\n",
      "  Attack Epoch [1200/2000], Average Loss: 0.098144\n",
      "  Attack Epoch [1250/2000], Average Loss: 0.098070\n",
      "  Attack Epoch [1300/2000], Average Loss: 0.098084\n",
      "  Attack Epoch [1350/2000], Average Loss: 0.098141\n",
      "  Attack Epoch [1400/2000], Average Loss: 0.098130\n",
      "  Attack Epoch [1450/2000], Average Loss: 0.098063\n",
      "  Attack Epoch [1500/2000], Average Loss: 0.098113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attack Epoch [1550/2000], Average Loss: 0.098107\n",
      "  Attack Epoch [1600/2000], Average Loss: 0.098074\n",
      "  Attack Epoch [1650/2000], Average Loss: 0.098171\n",
      "  Attack Epoch [1700/2000], Average Loss: 0.098049\n",
      "  Attack Epoch [1750/2000], Average Loss: 0.098135\n",
      "  Attack Epoch [1800/2000], Average Loss: 0.098018\n",
      "  Attack Epoch [1850/2000], Average Loss: 0.098074\n",
      "  Attack Epoch [1900/2000], Average Loss: 0.098058\n",
      "  Attack Epoch [1950/2000], Average Loss: 0.098114\n",
      "  Attack Epoch [2000/2000], Average Loss: 0.098063\n",
      "  Final Attack Model Average Loss: 0.098063\n",
      "\n",
      "Attack model training finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Thay th·∫ø n·ªôi dung Cell 12 ---\n",
    "from phase2_train_attack_model import train_attack_model # Import h√†m train m·ªõi\n",
    "\n",
    "attack_models = {}\n",
    "methods = [\"label_only\", \"vector_based\", \"score_based\", \"one_hot\"]\n",
    "epochs_attack = 2000 # Gi·ªØ nguy√™n s·ªë epochs ho·∫∑c ƒëi·ªÅu ch·ªânh\n",
    "\n",
    "attack_lr = 5e-5   # TH·ª¨ GI√Å TR·ªä TH·∫§P H∆†N   # Learning rate cho attack model m·ªõi\n",
    "attack_batch_size = 32 # Batch size cho attack model training\n",
    "\n",
    "# Device ƒë·ªÉ train attack model\n",
    "device_train_attack = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Training Attack Models on {device_train_attack}...\")\n",
    "\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"\\nTraining attack model for: {method}\")\n",
    "    # L·∫•y d·ªØ li·ªáu hu·∫•n luy·ªán ƒë√£ t·∫°o ·ªü cell tr√™n\n",
    "    vecs = attack_train_data[method][\"vectors\"]\n",
    "    imgs_target = attack_train_data[method][\"images\"]\n",
    "\n",
    "    if len(vecs) == 0:\n",
    "        print(f\"  Skipping {method} due to no training data.\")\n",
    "        attack_models[method] = None\n",
    "        continue\n",
    "\n",
    "    print(f\"  Training with {len(vecs)} samples...\")\n",
    "    # Hu·∫•n luy·ªán attack model (s·ª≠ d·ª•ng h√†m train_attack_model ƒë√£ s·ª≠a v·ªõi ki·∫øn tr√∫c m·ªõi)\n",
    "    attack_models[method] = train_attack_model(\n",
    "        vecs,\n",
    "        imgs_target,\n",
    "        epochs=epochs_attack,\n",
    "        batch_size=attack_batch_size,\n",
    "        lr=attack_lr,\n",
    "        device=device_train_attack\n",
    "    ) # H√†m n√†y tr·∫£ v·ªÅ model tr√™n CPU\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"\\nAttack model training finished.\")\n",
    "# --- K·∫øt th√∫c thay th·∫ø Cell 12 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1dac89",
   "metadata": {},
   "source": [
    "## Step 7: Reconstruct and Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8dea5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import phase3_reconstruct\n",
    "importlib.reload(phase3_reconstruct)\n",
    "\n",
    "from phase3_reconstruct import reconstruct_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a5dfee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from \"D:\\\\Computer Science\\\\ELTE's MSc\\\\Data Security\\\\model_inversion_mnist - Copy - Good lastesr version\\\\model_inversion_mnist\\\\utils.py\">"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f3a6659",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_test_cpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- S·ª≠a l·∫°i ph·∫ßn t·∫°o dictionary `results` trong Cell 15 ---\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# method_labels ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a ·ªü ƒë·∫ßu cell:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# methods = list(method_labels.keys())\u001b[39;00m\n\u001b[0;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;66;03m# Kh·ªüi t·∫°o results r·ªóng\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m ground_truth_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mimages_test_cpu\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;66;03m# ·∫¢nh g·ªëc ƒë·ªÉ v·∫Ω\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReconstructing test images...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images_test_cpu' is not defined"
     ]
    }
   ],
   "source": [
    "# --- CELL 15: T√°i T·∫°o ·∫¢nh Test v√† V·∫Ω Bi·ªÉu ƒê·ªì ---\n",
    "\n",
    "# Import c√°c th∆∞ vi·ªán v√† h√†m c·∫ßn thi·∫øt cho cell n√†y\n",
    "import torch\n",
    "from phase3_reconstruct import reconstruct_images\n",
    "from utils import plot_comparison # H√†m v·∫Ω bi·ªÉu ƒë·ªì t·ª´ utils.py\n",
    "from attacks.label_only_attack import recover_confidence_vector # H√†m kh√¥i ph·ª•c vector label-only\n",
    "# import matplotlib.pyplot as plt # Kh√¥ng c·∫ßn import l·∫°i n·∫øu ƒë√£ import ·ªü ƒë·∫ßu notebook\n",
    "\n",
    "# --- Ph·∫ßn Kh·ªüi t·∫°o v√† L·∫•y D·ªØ li·ªáu ---\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a nh√£n cho c√°c h√†ng tr√™n bi·ªÉu ƒë·ªì\n",
    "method_labels = {\n",
    "    \"label_only\": \"Label only\",\n",
    "    \"vector_based\": \"Vector-based\",\n",
    "    \"score_based\": \"Score-based\",\n",
    "    \"one_hot\": \"One hot\"\n",
    "}\n",
    "# L·∫•y danh s√°ch c√°c ph∆∞∆°ng th·ª©c (ƒë·∫£m b·∫£o th·ª© t·ª± nh·∫•t qu√°n v·ªõi c√°c cell tr∆∞·ªõc)\n",
    "methods = list(method_labels.keys())\n",
    "\n",
    "# Kh·ªüi t·∫°o dictionary ƒë·ªÉ l∆∞u k·∫øt qu·∫£ t√°i t·∫°o\n",
    "results = {}\n",
    "\n",
    "# !!! S·ª¨A L·ªñI NameError ·ªû ƒê√ÇY !!!\n",
    "# L·∫•y 10 ·∫£nh/nh√£n test g·ªëc (bi·∫øn `images`, `labels` ph·∫£i ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a ·ªü Cell 10)\n",
    "# Chuy·ªÉn ch√∫ng v·ªÅ CPU v√† t·∫°o b·∫£n sao l√†m ground truth cho bi·ªÉu ƒë·ªì\n",
    "try:\n",
    "    images_test_cpu = images.cpu()  # ƒê·ªãnh nghƒ©a images_test_cpu\n",
    "    labels_test_cpu = labels.cpu()  # ƒê·ªãnh nghƒ©a labels_test_cpu\n",
    "    ground_truth_imgs = images_test_cpu.detach().clone() # ƒê·ªãnh nghƒ©a ground_truth_imgs\n",
    "except NameError:\n",
    "    print(\"L·ªñI: Bi·∫øn 'images' ho·∫∑c 'labels' (10 ·∫£nh/nh√£n test) ch∆∞a ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.\")\n",
    "    print(\"H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ ch·∫°y th√†nh c√¥ng Cell 10.\")\n",
    "    # G√°n gi√° tr·ªã t·∫°m ƒë·ªÉ tr√°nh l·ªói ti·∫øp theo, nh∆∞ng bi·ªÉu ƒë·ªì s·∫Ω kh√¥ng ƒë√∫ng\n",
    "    ground_truth_imgs = None\n",
    "    images_test_cpu = torch.zeros(10, 1, 28, 28) # Gi√° tr·ªã t·∫°m\n",
    "    labels_test_cpu = torch.zeros(10, dtype=torch.long) # Gi√° tr·ªã t·∫°m\n",
    "\n",
    "# C√†i ƒë·∫∑t device v√† models (ƒë·∫£m b·∫£o ch√∫ng ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán/chu·∫©n b·ªã ·ªü c√°c cell tr∆∞·ªõc)\n",
    "device_reconstruct = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "try:\n",
    "    target_model.to(device_reconstruct).eval()\n",
    "    # shadow_model n√™n ·ªü tr√™n CPU theo h√†m recover_confidence_vector\n",
    "    shadow_model.cpu().eval()\n",
    "except NameError:\n",
    "    print(\"L·ªñI: `target_model` ho·∫∑c `shadow_model` ch∆∞a ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a/hu·∫•n luy·ªán.\")\n",
    "    # X·ª≠ l√Ω l·ªói ho·∫∑c tho√°t\n",
    "\n",
    "# L·∫•y mu, sigma t·ª´ Cell 11 (c·∫ßn cho 'label_only')\n",
    "try:\n",
    "    # Gi·∫£ s·ª≠ bi·∫øn mu v√† sigma t·ªìn t·∫°i t·ª´ Cell 11\n",
    "    mu_for_recon = mu\n",
    "    sigma_for_recon = sigma\n",
    "    print(f\"S·ª≠ d·ª•ng mu={mu_for_recon:.4f}, sigma={sigma_for_recon} ƒë·ªÉ t√°i t·∫°o label_only.\")\n",
    "except NameError:\n",
    "     print(\"L·ªñI: Bi·∫øn `mu` v√† `sigma` kh√¥ng t√¨m th·∫•y t·ª´ Cell 11. Kh√¥ng th·ªÉ t√°i t·∫°o cho label_only.\")\n",
    "     mu_for_recon = 0.5 # G√°n gi√° tr·ªã t·∫°m ƒë·ªÉ tr√°nh l·ªói, nh∆∞ng k·∫øt qu·∫£ label_only s·∫Ω sai\n",
    "     sigma_for_recon = 0.1\n",
    "\n",
    "# --- Ph·∫ßn T√°i T·∫°o ·∫¢nh ---\n",
    "print(\"\\nƒêang t√°i t·∫°o ·∫£nh th·ª≠ nghi·ªám...\")\n",
    "\n",
    "# L·∫∑p qua t·ª´ng ph∆∞∆°ng ph√°p t·∫•n c√¥ng\n",
    "for method in methods:\n",
    "    print(f\" ƒêang t√°i t·∫°o cho: {method}\")\n",
    "\n",
    "    # L·∫•y attack model ƒë√£ hu·∫•n luy·ªán t∆∞∆°ng ·ª©ng (t·ª´ Cell 12)\n",
    "    # attack_models l√† dictionary ch·ª©a c√°c model ƒë√£ train\n",
    "    attack_model_method = attack_models.get(method)\n",
    "\n",
    "    # Ki·ªÉm tra xem model c√≥ t·ªìn t·∫°i kh√¥ng (tr∆∞·ªùng h·ª£p hu·∫•n luy·ªán l·ªói)\n",
    "    if attack_model_method is None:\n",
    "        print(f\"  B·ªè qua {method} v√¨ attack model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán.\")\n",
    "        label_name = method_labels[method] # L·∫•y nh√£n ƒë√∫ng\n",
    "        # T·∫°o ·∫£nh ƒëen ho·∫∑c placeholder n·∫øu model kh√¥ng c√≥\n",
    "        results[label_name] = torch.zeros_like(images_test_cpu)\n",
    "        continue\n",
    "\n",
    "    # Chuy·ªÉn model sang device v√† ch·∫ø ƒë·ªô eval\n",
    "    attack_model_method = attack_model_method.to(device_reconstruct).eval()\n",
    "    vectors_to_reconstruct_list = [] # List ƒë·ªÉ l∆∞u vector c·ªßa 10 ·∫£nh test\n",
    "\n",
    "    # T·∫°o vector tin c·∫≠y cho t·ª´ng ·∫£nh test theo ph∆∞∆°ng ph√°p 'method'\n",
    "    with torch.no_grad(): # Kh√¥ng c·∫ßn t√≠nh gradient ·ªü b∆∞·ªõc n√†y\n",
    "        for i in range(len(images_test_cpu)): # L·∫∑p qua 10 ·∫£nh test\n",
    "            img_test_device = images_test_cpu[i].unsqueeze(0).to(device_reconstruct) # Th√™m batch dim=1 v√† chuy·ªÉn sang device\n",
    "            label_test = labels_test_cpu[i].item() # L·∫•y nh√£n d·∫°ng s·ªë nguy√™n\n",
    "\n",
    "            # T·∫°o vector test d·ª±a tr√™n ph∆∞∆°ng ph√°p\n",
    "            if method == \"label_only\":\n",
    "                 vec_test = recover_confidence_vector(\n",
    "                     shadow_model, mu_for_recon, label_test,\n",
    "                     num_classes=10, sigma=sigma_for_recon\n",
    "                 ) # H√†m n√†y tr·∫£ v·ªÅ CPU\n",
    "            elif method == \"vector_based\":\n",
    "                 vec_test = torch.softmax(target_model(img_test_device), dim=1).squeeze().cpu()\n",
    "            elif method == \"score_based\":\n",
    "                 prob_sb = torch.softmax(target_model(img_test_device), dim=1).squeeze().cpu()\n",
    "                 max_idx_sb = torch.argmax(prob_sb)\n",
    "                 vec_test = torch.zeros_like(prob_sb)\n",
    "                 if 0 <= max_idx_sb < len(vec_test):\n",
    "                     vec_test[max_idx_sb] = prob_sb[max_idx_sb]\n",
    "                 else: # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p index l·ªói (d√π hi·∫øm)\n",
    "                      vec_test[0] = 1.0 # Ho·∫∑c x·ª≠ l√Ω kh√°c\n",
    "            elif method == \"one_hot\":\n",
    "                 pred_oh = torch.argmax(target_model(img_test_device), dim=1).item()\n",
    "                 vec_test = torch.zeros(10) # K√≠ch th∆∞·ªõc num_classes\n",
    "                 if 0 <= pred_oh < 10: # Ki·ªÉm tra index h·ª£p l·ªá\n",
    "                     vec_test[pred_oh] = 1.0\n",
    "                 else: # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p index l·ªói\n",
    "                      vec_test[0] = 1.0 # Ho·∫∑c x·ª≠ l√Ω kh√°c\n",
    "\n",
    "            vectors_to_reconstruct_list.append(vec_test.cpu()) # ƒê·∫£m b·∫£o m·ªçi vector ƒë·ªÅu ·ªü CPU\n",
    "\n",
    "    # Gh√©p c√°c vector th√†nh m·ªôt batch v√† chuy·ªÉn sang device ƒë·ªÉ t√°i t·∫°o\n",
    "    vecs_to_reconstruct = torch.stack(vectors_to_reconstruct_list).to(device_reconstruct)\n",
    "\n",
    "    # T√°i t·∫°o ·∫£nh b·∫±ng attack model t∆∞∆°ng ·ª©ng\n",
    "    with torch.no_grad():\n",
    "        recon = reconstruct_images(attack_model_method, vecs_to_reconstruct)\n",
    "\n",
    "    # L∆∞u k·∫øt qu·∫£ v√†o dictionary v·ªõi nh√£n ng·∫Øn g·ªçn l√†m key\n",
    "    label_name = method_labels[method]\n",
    "    results[label_name] = recon.cpu().detach() # Chuy·ªÉn k·∫øt qu·∫£ v·ªÅ CPU v√† detach kh·ªèi graph\n",
    "\n",
    "# --- Ph·∫ßn V·∫Ω Bi·ªÉu ƒê·ªì ---\n",
    "print(\"\\nƒêang v·∫Ω bi·ªÉu ƒë·ªì so s√°nh...\")\n",
    "\n",
    "if ground_truth_imgs is not None:\n",
    "    # Ki·ªÉm tra xem c√≥ ƒë·ªß k·∫øt qu·∫£ cho c√°c ph∆∞∆°ng ph√°p kh√¥ng\n",
    "     if len(results) == len(methods):\n",
    "         plot_comparison(ground_truth_imgs, results, title='Model Inversion Comparison')\n",
    "     else:\n",
    "          # In c·∫£nh b√°o n·∫øu s·ªë l∆∞·ª£ng k·∫øt qu·∫£ kh√¥ng kh·ªõp s·ªë ph∆∞∆°ng ph√°p\n",
    "          print(f\"Warning: Number of results ({len(results)}) does not match number of methods ({len(methods)}). Plot might be incomplete.\")\n",
    "          # V·∫´n v·∫Ω v·ªõi nh·ªØng g√¨ c√≥ ƒë∆∞·ª£c\n",
    "          plot_comparison(ground_truth_imgs, results, title='Model Inversion Comparison (Incomplete)')\n",
    "\n",
    "else:\n",
    "    print(\"Kh√¥ng th·ªÉ l·∫•y ·∫£nh g·ªëc ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.\")\n",
    "\n",
    "# --- K·∫øt th√∫c Cell 15 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29daccb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (with torch)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
