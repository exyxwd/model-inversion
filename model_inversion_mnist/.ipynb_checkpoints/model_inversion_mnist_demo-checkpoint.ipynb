{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8f4380",
   "metadata": {},
   "source": [
    "# 🧠 Model Inversion on MNIST using Label-only Attack\n",
    "This notebook demonstrates how to reconstruct images using model inversion attacks with only label information, following the structure of the paper: **'Label-only Model Inversion Attack: The Attack that Requires the Least'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18a5cc",
   "metadata": {},
   "source": [
    "## 📥 Step 1: Setup and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccae809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (0.21.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (3.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3393279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfad26eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14233691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipykernel in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (1.8.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (8.28.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (308)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec torch_env in C:\\Users\\USER\\AppData\\Roaming\\jupyter\\kernels\\torch_env\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install ipykernel\n",
    "!python -m ipykernel install --user --name torch_env --display-name \"Python (with torch)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d863b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec torch_env in C:\\Users\\USER\\AppData\\Roaming\\jupyter\\kernels\\torch_env\n"
     ]
    }
   ],
   "source": [
    "!python -m ipykernel install --user --name=torch_env --display-name \"Python (with torch)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19bedffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed30f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch.optim as optim\n",
    "from utils import compute_error_rate, add_gaussian_noise # Đảm bảo import đủ\n",
    "import torch.nn as nn # Import nn\n",
    "\n",
    "\n",
    "# Thêm thư mục hiện tại vào sys.path để import được các file .py bên cạnh\n",
    "sys.path.append(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8647f3",
   "metadata": {},
   "source": [
    "## 📁 Step 2: Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157ac3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000, Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "from data_loader import load_mnist_data\n",
    "train_set, test_set = load_mnist_data()\n",
    "print(f\"Training samples: {len(train_set)}, Test samples: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b5dc2",
   "metadata": {},
   "source": [
    "## 🏗️ Step 3: Build a Dummy Target Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b009b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Target CNN...\n",
      "Epoch 1, Target Model Loss: 0.1196, Accuracy: 96.43%\n",
      "Epoch 2, Target Model Loss: 0.0388, Accuracy: 98.77%\n",
      "Epoch 3, Target Model Loss: 0.0295, Accuracy: 99.07%\n",
      "Epoch 4, Target Model Loss: 0.0224, Accuracy: 99.25%\n",
      "Epoch 5, Target Model Loss: 0.0170, Accuracy: 99.44%\n",
      "Target CNN training finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TargetCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1152, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Thay thế nội dung Cell 9 ---\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset # Thêm Subset nếu cần\n",
    "\n",
    "# Định nghĩa TargetCNN\n",
    "class TargetCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        # Tính toán kích thước input cho lớp Linear đầu tiên cẩn thận\n",
    "        # Ví dụ MNIST 28x28 -> qua 3 MaxPool2d -> 28/2/2/2 = 3.5 -> làm tròn xuống 3\n",
    "        # Kích thước cuối cùng là 128 kênh * 3 * 3\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*3*3, 256), nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Khởi tạo và huấn luyện TargetCNN\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "target_model = TargetCNN().to(device) # Sử dụng CNN\n",
    "\n",
    "# Chuẩn bị DataLoader để train target model (ví dụ dùng toàn bộ train_set)\n",
    "# Đảm bảo bạn đã load train_set ở Cell 8\n",
    "loader_target_train = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "\n",
    "# Huấn luyện target_model\n",
    "optimizer = optim.Adam(target_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5 # Số epochs ví dụ (có thể cần nhiều hơn)\n",
    "print(\"Training Target CNN...\")\n",
    "for epoch in range(epochs):\n",
    "    target_model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for imgs, labels in loader_target_train:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = target_model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total_train\n",
    "    accuracy = 100 * correct_train / total_train\n",
    "    print(f\"Epoch {epoch+1}, Target Model Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Target CNN training finished.\")\n",
    "target_model.eval() # Chuyển sang chế độ đánh giá\n",
    "# --- Kết thúc thay thế Cell 9 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebddb44",
   "metadata": {},
   "source": [
    "## 🧪 Step 4: Prepare Sample Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d708590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [test_set[i] for i in range(10)]\n",
    "images = torch.stack([img for img, _ in samples])\n",
    "labels = torch.tensor([label for _, label in samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce506410",
   "metadata": {},
   "source": [
    "## 🧩 Step 5: Generate Confidence Vectors from 4 Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ff27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shadow Model...\n",
      "  Shadow Epoch [20/100], Loss: 0.1895\n",
      "  Shadow Epoch [40/100], Loss: 0.1525\n",
      "  Shadow Epoch [60/100], Loss: 0.1219\n",
      "  Shadow Epoch [80/100], Loss: 0.1057\n",
      "  Shadow Epoch [100/100], Loss: 0.0890\n",
      "Shadow Model training finished.\n",
      "Processing label_only...\n",
      "Calculated mu for label-only: 0.7800\n",
      "label_only: vectors torch.Size([10, 10]), targets torch.Size([10, 1, 28, 28])\n",
      "Processing other methods...\n",
      " Processing vector_based...\n",
      " vector_based: vectors torch.Size([10, 10]), targets torch.Size([10, 1, 28, 28])\n",
      " Processing score_based...\n",
      " score_based: vectors torch.Size([10, 10]), targets torch.Size([10, 1, 28, 28])\n",
      " Processing one_hot...\n",
      " one_hot: vectors torch.Size([10, 10]), targets torch.Size([10, 1, 28, 28])\n",
      "Confidence vector generation finished for all methods.\n",
      "\n",
      "--- Checking Generated Vectors (First Sample) ---\n",
      "Sample Label: 7\n",
      "\n",
      "Method: label_only\n",
      "tensor([0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.0000, 0.1110,\n",
      "        0.1110])\n",
      "\n",
      "Method: vector_based\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "\n",
      "Method: score_based\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "\n",
      "Method: one_hot\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Computer Science\\ELTE's MSc\\Data Security\\model_inversion_mnist - Copy - Good lastesr version\\model_inversion_mnist\\attacks\\label_only_attack.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  phi_inv_mu_tensor = torch.tensor(phi_inv_mu, dtype=torch.float32, device='cpu') # Ensure tensor\n"
     ]
    }
   ],
   "source": [
    "# --- Thay thế nội dung Cell 11 ---\n",
    "from attacks.label_only_attack import train_shadow_model # Giữ lại import\n",
    "from utils import add_gaussian_noise, compute_error_rate # Đảm bảo import đủ\n",
    "from phase1_vector_recovery import generate_confidence_vectors # Giữ lại import\n",
    "\n",
    "# 1. Chuẩn bị dữ liệu cho Shadow Model và tính mu\n",
    "n_aux = 1000 # Số lượng mẫu phụ trợ dương\n",
    "n_neg = 100 # Số lượng mẫu phụ trợ âm (ví dụ)\n",
    "aux_indices = list(range(n_aux))\n",
    "# Đảm bảo n_neg đã được định nghĩa (ví dụ: n_neg = 100 hoặc n_neg = n_aux)\n",
    "neg_indices = list(range(n_aux, n_aux + n_neg)) # Bắt đầu ngay sau aux_indices\n",
    "\n",
    "# Lấy aux_images và aux_labels (positive samples cho shadow & tính mu)\n",
    "aux_images_list = []\n",
    "aux_labels_list = []\n",
    "for i in aux_indices:\n",
    "    img, label = train_set[i]\n",
    "    aux_images_list.append(img)\n",
    "    aux_labels_list.append(label)\n",
    "aux_images = torch.stack(aux_images_list)\n",
    "aux_labels = torch.tensor(aux_labels_list) # Nhãn gốc của aux_images\n",
    "\n",
    "# Lấy d_neg (negative samples cho shadow)\n",
    "d_neg = torch.stack([train_set[i][0] for i in neg_indices])\n",
    "\n",
    "# 2. Huấn luyện Shadow Model (trên CPU)\n",
    "# Hàm train_shadow_model đã được cập nhật để nhận D_aux, D_neg\n",
    "shadow_model = train_shadow_model(aux_images, d_neg, epochs=100) # Có thể điều chỉnh epochs\n",
    "\n",
    "# 3. Tạo Confidence Vectors\n",
    "vectors_by_method = {}\n",
    "targets_by_method = {} # Thêm dict này nếu bạn muốn lưu target images tương ứng\n",
    "\n",
    "# Chuyển dữ liệu test (images, labels từ Cell 10) và models sang device\n",
    "images = images.to(device) # images, labels là 10 sample test ban đầu\n",
    "labels = labels.cpu() # Giữ labels trên CPU vì dùng .item()\n",
    "target_model.to(device).eval()\n",
    "aux_images = aux_images.to(device) # aux_images cũng cần trên device để tính mu\n",
    "aux_labels = aux_labels.to(device) # aux_labels tương ứng\n",
    "\n",
    "# -- Xử lý riêng cho label_only --\n",
    "print(\"Processing label_only...\")\n",
    "sigma = 0.3 # Giá trị sigma\n",
    "noisy_aux = add_gaussian_noise(aux_images, sigma=sigma).to(device)\n",
    "mu = compute_error_rate(target_model, noisy_aux, aux_labels, device)\n",
    "print(f\"Calculated mu for label-only: {mu:.4f}\")\n",
    "\n",
    "vectors_label_only, targets_label_only = generate_confidence_vectors(\n",
    "    images=images.cpu(),    # Truyền dữ liệu test gốc (trên CPU cho hàm này)\n",
    "    labels=labels.cpu(),    # Nhãn test gốc (trên CPU)\n",
    "    target_model=target_model, # Model target\n",
    "    method=\"label_only\",\n",
    "    shadow_model=shadow_model, # Model shadow đã train\n",
    "    mu=mu,                 # mu đã tính\n",
    "    sigma=sigma,           # sigma\n",
    "    num_classes=10,\n",
    "    device=device          # device để target_model chạy nếu cần bên trong hàm\n",
    ")\n",
    "vectors_by_method[\"label_only\"] = vectors_label_only\n",
    "targets_by_method[\"label_only\"] = targets_label_only # Lưu ảnh gốc làm target\n",
    "print(f\"label_only: vectors {vectors_label_only.shape}, targets {targets_label_only.shape}\")\n",
    "\n",
    "\n",
    "# -- Xử lý các phương thức còn lại --\n",
    "other_methods = [\"vector_based\", \"score_based\", \"one_hot\"]\n",
    "print(\"Processing other methods...\")\n",
    "for method in other_methods:\n",
    "    print(f\" Processing {method}...\")\n",
    "    vectors, targets = generate_confidence_vectors(\n",
    "        images=images.cpu(),\n",
    "        labels=labels.cpu(),\n",
    "        target_model=target_model,\n",
    "        method=method,\n",
    "        # Không cần shadow_model, mu, sigma\n",
    "        num_classes=10,\n",
    "        device=device\n",
    "    )\n",
    "    vectors_by_method[method] = vectors\n",
    "    targets_by_method[method] = targets # Lưu ảnh gốc làm target\n",
    "    print(f\" {method}: vectors {vectors.shape}, targets {targets.shape}\")\n",
    "\n",
    "print(\"Confidence vector generation finished for all methods.\")\n",
    "# --- Kết thúc thay thế Cell 11 ---\n",
    "\n",
    "\n",
    "# Thêm vào cuối Cell 11\n",
    "print(\"\\n--- Checking Generated Vectors (First Sample) ---\")\n",
    "target_model.to(device) # Đảm bảo model trên device\n",
    "sample_image_cpu = images[0].cpu() # Lấy ảnh đầu tiên (CPU)\n",
    "sample_image_device = images[0].to(device) # Lấy ảnh đầu tiên (Device)\n",
    "sample_label = labels[0].item() # Lấy nhãn đầu tiên\n",
    "\n",
    "print(f\"Sample Label: {sample_label}\")\n",
    "\n",
    "# Label-only\n",
    "print(\"\\nMethod: label_only\")\n",
    "# Lấy vector đã tính trước đó\n",
    "print(torch.round(vectors_by_method[\"label_only\"][0] * 1000) / 1000) # Làm tròn 3 chữ số\n",
    "\n",
    "# Vector-based (Tính lại cho mẫu đầu tiên)\n",
    "print(\"\\nMethod: vector_based\")\n",
    "with torch.no_grad():\n",
    "    vec_vb = torch.softmax(target_model(sample_image_device.unsqueeze(0)), dim=1).squeeze()\n",
    "print(torch.round(vec_vb.cpu() * 1000) / 1000)\n",
    "\n",
    "# Score-based (Tính lại cho mẫu đầu tiên)\n",
    "print(\"\\nMethod: score_based\")\n",
    "with torch.no_grad():\n",
    "    prob_sb = torch.softmax(target_model(sample_image_device.unsqueeze(0)), dim=1).squeeze()\n",
    "    max_idx_sb = torch.argmax(prob_sb)\n",
    "    vec_sb = torch.zeros_like(prob_sb)\n",
    "    vec_sb[max_idx_sb] = prob_sb[max_idx_sb]\n",
    "print(torch.round(vec_sb.cpu() * 1000) / 1000)\n",
    "\n",
    "# One-hot (Tính lại cho mẫu đầu tiên)\n",
    "print(\"\\nMethod: one_hot\")\n",
    "with torch.no_grad():\n",
    "     pred_oh = torch.argmax(target_model(sample_image_device.unsqueeze(0)), dim=1).item()\n",
    "vec_oh = torch.zeros(10)\n",
    "vec_oh[pred_oh] = 1.0\n",
    "print(torch.round(vec_oh.cpu() * 1000) / 1000)\n",
    "\n",
    "print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1750ce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data for Attack Models...\n",
      "Using sigma=0.3, mu=0.78 from previous cell for label_only training data generation.\n",
      " Generating attack training data...\n",
      " Stacking tensors...\n",
      " Method label_only: Created 1000 training pairs.\n",
      " Method vector_based: Created 1000 training pairs.\n",
      " Method score_based: Created 1000 training pairs.\n",
      " Method one_hot: Created 1000 training pairs.\n",
      "Finished generating training data for Attack Models.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL MỚI: Chuẩn bị dữ liệu huấn luyện cho Attack Models ---\n",
    "from torch.utils.data import TensorDataset, DataLoader # Thêm import nếu chưa có ở đầu notebook\n",
    "from attacks.label_only_attack import recover_confidence_vector # Import hàm này\n",
    "\n",
    "print(\"Generating training data for Attack Models...\")\n",
    "\n",
    "# Dữ liệu phụ trợ bạn dùng để train shadow model và tính mu\n",
    "# aux_images, aux_labels (đã có từ Cell 11)\n",
    "# Giả định aux_images, aux_labels đang ở trên CPU sau khi train shadow_model\n",
    "# Nếu không, chuyển về CPU: aux_images = aux_images.cpu(); aux_labels = aux_labels.cpu()\n",
    "\n",
    "attack_train_data = {\n",
    "    \"label_only\": {\"vectors\": [], \"images\": []},\n",
    "    \"vector_based\": {\"vectors\": [], \"images\": []},\n",
    "    \"score_based\": {\"vectors\": [], \"images\": []},\n",
    "    \"one_hot\": {\"vectors\": []} # One-hot không cần ảnh target vì vector chỉ phụ thuộc label dự đoán\n",
    "                               # Nhưng để nhất quán, ta vẫn thêm ảnh target\n",
    "}\n",
    "# Chỉnh sửa: Thêm images vào one_hot để cấu trúc nhất quán\n",
    "attack_train_data[\"one_hot\"][\"images\"] = []\n",
    "\n",
    "\n",
    "# Device và models (đảm bảo chúng ở trạng thái và device phù hợp)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "target_model.to(device).eval()\n",
    "# shadow_model đã được train và trả về CPU trong hàm train_shadow_model\n",
    "shadow_model.cpu().eval()\n",
    "\n",
    "# Lấy các giá trị mu và sigma đã dùng/tính ở Cell 11 cho label_only\n",
    "# Bạn cần đảm bảo biến sigma và mu này tồn tại từ Cell 11\n",
    "# sigma_for_label_only = 0.3 # Ví dụ lấy từ lần chạy trước\n",
    "# mu_for_label_only = 0.73    # Ví dụ lấy từ lần chạy trước\n",
    "# HOẶC TÍNH LẠI Ở ĐÂY nếu cần\n",
    "try:\n",
    "    # Giả sử sigma và mu đã được định nghĩa ở cell trước\n",
    "    sigma_for_label_only = sigma\n",
    "    mu_for_label_only = mu\n",
    "    print(f\"Using sigma={sigma_for_label_only}, mu={mu_for_label_only} from previous cell for label_only training data generation.\")\n",
    "except NameError:\n",
    "    print(\"Error: sigma and mu not defined from previous cell. Please run Cell 11 again.\")\n",
    "    # Hoặc đặt giá trị mặc định/tính lại ở đây nếu logic cho phép\n",
    "    # Ví dụ tính lại (cần aux_images, aux_labels trên device):\n",
    "    # sigma_for_label_only = 0.3\n",
    "    # noisy_aux_temp = add_gaussian_noise(aux_images.to(device), sigma=sigma_for_label_only)\n",
    "    # mu_for_label_only = compute_error_rate(target_model, noisy_aux_temp, aux_labels.to(device), device)\n",
    "    # print(f\"Recalculated sigma={sigma_for_label_only}, mu={mu_for_label_only}\")\n",
    "\n",
    "\n",
    "# --- Tạo dữ liệu huấn luyện ---\n",
    "print(\" Generating attack training data...\")\n",
    "\n",
    "# Sử dụng DataLoader để xử lý hiệu quả aux_images\n",
    "# Tạo dataset từ aux_images (CPU) và aux_labels (CPU)\n",
    "temp_aux_dataset = TensorDataset(aux_images.cpu(), aux_labels.cpu())\n",
    "temp_aux_loader = DataLoader(temp_aux_dataset, batch_size=128) # Xử lý theo batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_batch_cpu, label_batch_cpu in temp_aux_loader:\n",
    "        # Chuyển batch lên device để đưa vào target_model\n",
    "        img_batch_device = img_batch_cpu.to(device)\n",
    "        softmax_output = torch.softmax(target_model(img_batch_device), dim=1)\n",
    "\n",
    "        for i in range(len(img_batch_cpu)):\n",
    "            img_orig = img_batch_cpu[i]    # Ảnh gốc (CPU)\n",
    "            label_orig = label_batch_cpu[i].item() # Nhãn gốc (int)\n",
    "\n",
    "            # --- Label-only ---\n",
    "            vec_lo = recover_confidence_vector(\n",
    "                shadow_model, mu_for_label_only, label_orig,\n",
    "                num_classes=10, sigma=sigma_for_label_only\n",
    "            )\n",
    "            attack_train_data[\"label_only\"][\"vectors\"].append(vec_lo)\n",
    "            attack_train_data[\"label_only\"][\"images\"].append(img_orig)\n",
    "\n",
    "            # --- Vector-based ---\n",
    "            vec_vb = softmax_output[i].cpu() # Vector từ target model (chuyển về CPU)\n",
    "            attack_train_data[\"vector_based\"][\"vectors\"].append(vec_vb)\n",
    "            attack_train_data[\"vector_based\"][\"images\"].append(img_orig)\n",
    "\n",
    "            # --- Score-based ---\n",
    "            prob_sb = vec_vb\n",
    "            max_idx_sb = torch.argmax(prob_sb)\n",
    "            vec_sb = torch.zeros_like(prob_sb)\n",
    "            if 0 <= max_idx_sb < len(vec_sb): # Check index bounds\n",
    "                 vec_sb[max_idx_sb] = prob_sb[max_idx_sb]\n",
    "            attack_train_data[\"score_based\"][\"vectors\"].append(vec_sb)\n",
    "            attack_train_data[\"score_based\"][\"images\"].append(img_orig)\n",
    "\n",
    "            # --- One-hot ---\n",
    "            pred_oh = torch.argmax(prob_sb).item() # Lấy dự đoán từ softmax\n",
    "            vec_oh = torch.zeros_like(prob_sb)\n",
    "            if 0 <= pred_oh < len(vec_oh): # Check index bounds\n",
    "                 vec_oh[pred_oh] = 1.0\n",
    "            attack_train_data[\"one_hot\"][\"vectors\"].append(vec_oh)\n",
    "            attack_train_data[\"one_hot\"][\"images\"].append(img_orig) # Thêm ảnh target\n",
    "\n",
    "# Chuyển list thành Tensor\n",
    "print(\" Stacking tensors...\")\n",
    "methods = [\"label_only\", \"vector_based\", \"score_based\", \"one_hot\"]\n",
    "for method in methods:\n",
    "    if attack_train_data[method][\"vectors\"]:\n",
    "        attack_train_data[method][\"vectors\"] = torch.stack(attack_train_data[method][\"vectors\"])\n",
    "        attack_train_data[method][\"images\"] = torch.stack(attack_train_data[method][\"images\"])\n",
    "        print(f\" Method {method}: Created {len(attack_train_data[method]['vectors'])} training pairs.\")\n",
    "    else:\n",
    "        print(f\" Method {method}: No training data generated.\")\n",
    "\n",
    "print(\"Finished generating training data for Attack Models.\")\n",
    "# --- Kết thúc CELL MỚI ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e093d",
   "metadata": {},
   "source": [
    "## 🧠 Step 6: Train Attack Model to Reconstruct Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad8fad2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Attack Models on cpu...\n",
      "\n",
      "Training attack model for: label_only\n",
      "  Training with 1000 samples...\n",
      " Training Attack Model (2000 epochs, lr=5e-05)...\n",
      "  Attack Epoch [50/2000], Average Loss: 0.205289\n",
      "  Attack Epoch [100/2000], Average Loss: 0.175248\n",
      "  Attack Epoch [150/2000], Average Loss: 0.140724\n",
      "  Attack Epoch [200/2000], Average Loss: 0.134202\n",
      "  Attack Epoch [250/2000], Average Loss: 0.101547\n",
      "  Attack Epoch [300/2000], Average Loss: 0.099778\n",
      "  Attack Epoch [350/2000], Average Loss: 0.099110\n",
      "  Attack Epoch [400/2000], Average Loss: 0.098797\n",
      "  Attack Epoch [450/2000], Average Loss: 0.098684\n",
      "  Attack Epoch [500/2000], Average Loss: 0.098588\n",
      "  Attack Epoch [550/2000], Average Loss: 0.098562\n",
      "  Attack Epoch [600/2000], Average Loss: 0.098577\n",
      "  Attack Epoch [650/2000], Average Loss: 0.098559\n",
      "  Attack Epoch [700/2000], Average Loss: 0.098441\n",
      "  Attack Epoch [750/2000], Average Loss: 0.098242\n",
      "  Attack Epoch [800/2000], Average Loss: 0.098335\n",
      "  Attack Epoch [850/2000], Average Loss: 0.098514\n",
      "  Attack Epoch [900/2000], Average Loss: 0.098339\n",
      "  Attack Epoch [950/2000], Average Loss: 0.098252\n",
      "  Attack Epoch [1000/2000], Average Loss: 0.098344\n",
      "  Attack Epoch [1050/2000], Average Loss: 0.098267\n",
      "  Attack Epoch [1100/2000], Average Loss: 0.098265\n",
      "  Attack Epoch [1150/2000], Average Loss: 0.098227\n",
      "  Attack Epoch [1200/2000], Average Loss: 0.098317\n",
      "  Attack Epoch [1250/2000], Average Loss: 0.098330\n",
      "  Attack Epoch [1300/2000], Average Loss: 0.098276\n",
      "  Attack Epoch [1350/2000], Average Loss: 0.098259\n",
      "  Attack Epoch [1400/2000], Average Loss: 0.098236\n",
      "  Attack Epoch [1450/2000], Average Loss: 0.098219\n",
      "  Attack Epoch [1500/2000], Average Loss: 0.098163\n",
      "  Attack Epoch [1550/2000], Average Loss: 0.098260\n",
      "  Attack Epoch [1600/2000], Average Loss: 0.098241\n",
      "  Attack Epoch [1650/2000], Average Loss: 0.098216\n",
      "  Attack Epoch [1700/2000], Average Loss: 0.098121\n",
      "  Attack Epoch [1750/2000], Average Loss: 0.098172\n",
      "  Attack Epoch [1800/2000], Average Loss: 0.098169\n",
      "  Attack Epoch [1850/2000], Average Loss: 0.098049\n",
      "  Attack Epoch [1900/2000], Average Loss: 0.098164\n",
      "  Attack Epoch [1950/2000], Average Loss: 0.098146\n",
      "  Attack Epoch [2000/2000], Average Loss: 0.098185\n",
      "  Final Attack Model Average Loss: 0.098185\n",
      "\n",
      "Training attack model for: vector_based\n",
      "  Training with 1000 samples...\n",
      " Training Attack Model (2000 epochs, lr=5e-05)...\n",
      "  Attack Epoch [50/2000], Average Loss: 0.218097\n",
      "  Attack Epoch [100/2000], Average Loss: 0.163566\n",
      "  Attack Epoch [150/2000], Average Loss: 0.139488\n",
      "  Attack Epoch [200/2000], Average Loss: 0.104036\n",
      "  Attack Epoch [250/2000], Average Loss: 0.100899\n",
      "  Attack Epoch [300/2000], Average Loss: 0.099464\n",
      "  Attack Epoch [350/2000], Average Loss: 0.099009\n",
      "  Attack Epoch [400/2000], Average Loss: 0.098633\n",
      "  Attack Epoch [450/2000], Average Loss: 0.098543\n",
      "  Attack Epoch [500/2000], Average Loss: 0.098243\n",
      "  Attack Epoch [550/2000], Average Loss: 0.098271\n",
      "  Attack Epoch [600/2000], Average Loss: 0.098034\n",
      "  Attack Epoch [650/2000], Average Loss: 0.098033\n",
      "  Attack Epoch [700/2000], Average Loss: 0.098155\n",
      "  Attack Epoch [750/2000], Average Loss: 0.097861\n",
      "  Attack Epoch [800/2000], Average Loss: 0.098025\n",
      "  Attack Epoch [850/2000], Average Loss: 0.097872\n",
      "  Attack Epoch [900/2000], Average Loss: 0.097898\n",
      "  Attack Epoch [950/2000], Average Loss: 0.097851\n",
      "  Attack Epoch [1000/2000], Average Loss: 0.097811\n",
      "  Attack Epoch [1050/2000], Average Loss: 0.097696\n",
      "  Attack Epoch [1100/2000], Average Loss: 0.097679\n",
      "  Attack Epoch [1150/2000], Average Loss: 0.097623\n",
      "  Attack Epoch [1200/2000], Average Loss: 0.097664\n",
      "  Attack Epoch [1250/2000], Average Loss: 0.097678\n",
      "  Attack Epoch [1300/2000], Average Loss: 0.097796\n",
      "  Attack Epoch [1350/2000], Average Loss: 0.097582\n",
      "  Attack Epoch [1400/2000], Average Loss: 0.097573\n",
      "  Attack Epoch [1450/2000], Average Loss: 0.097542\n",
      "  Attack Epoch [1500/2000], Average Loss: 0.097540\n",
      "  Attack Epoch [1550/2000], Average Loss: 0.097476\n",
      "  Attack Epoch [1600/2000], Average Loss: 0.097581\n",
      "  Attack Epoch [1650/2000], Average Loss: 0.097441\n",
      "  Attack Epoch [1700/2000], Average Loss: 0.097463\n",
      "  Attack Epoch [1750/2000], Average Loss: 0.097515\n",
      "  Attack Epoch [1800/2000], Average Loss: 0.097601\n",
      "  Attack Epoch [1850/2000], Average Loss: 0.097401\n",
      "  Attack Epoch [1900/2000], Average Loss: 0.097481\n",
      "  Attack Epoch [1950/2000], Average Loss: 0.097462\n",
      "  Attack Epoch [2000/2000], Average Loss: 0.097457\n",
      "  Final Attack Model Average Loss: 0.097457\n",
      "\n",
      "Training attack model for: score_based\n",
      "  Training with 1000 samples...\n",
      " Training Attack Model (2000 epochs, lr=5e-05)...\n",
      "  Attack Epoch [50/2000], Average Loss: 0.245818\n",
      "  Attack Epoch [100/2000], Average Loss: 0.194938\n",
      "  Attack Epoch [150/2000], Average Loss: 0.139533\n",
      "  Attack Epoch [200/2000], Average Loss: 0.134134\n",
      "  Attack Epoch [250/2000], Average Loss: 0.128326\n",
      "  Attack Epoch [300/2000], Average Loss: 0.100184\n",
      "  Attack Epoch [350/2000], Average Loss: 0.099191\n",
      "  Attack Epoch [400/2000], Average Loss: 0.098790\n",
      "  Attack Epoch [450/2000], Average Loss: 0.098512\n",
      "  Attack Epoch [500/2000], Average Loss: 0.098457\n",
      "  Attack Epoch [550/2000], Average Loss: 0.098359\n",
      "  Attack Epoch [600/2000], Average Loss: 0.098096\n",
      "  Attack Epoch [650/2000], Average Loss: 0.098256\n",
      "  Attack Epoch [700/2000], Average Loss: 0.098139\n",
      "  Attack Epoch [750/2000], Average Loss: 0.098172\n",
      "  Attack Epoch [800/2000], Average Loss: 0.098098\n",
      "  Attack Epoch [850/2000], Average Loss: 0.098032\n",
      "  Attack Epoch [900/2000], Average Loss: 0.097935\n",
      "  Attack Epoch [950/2000], Average Loss: 0.097945\n",
      "  Attack Epoch [1000/2000], Average Loss: 0.097846\n",
      "  Attack Epoch [1050/2000], Average Loss: 0.097966\n",
      "  Attack Epoch [1100/2000], Average Loss: 0.097869\n",
      "  Attack Epoch [1150/2000], Average Loss: 0.097807\n",
      "  Attack Epoch [1200/2000], Average Loss: 0.097876\n",
      "  Attack Epoch [1250/2000], Average Loss: 0.097846\n",
      "  Attack Epoch [1300/2000], Average Loss: 0.097894\n",
      "  Attack Epoch [1350/2000], Average Loss: 0.097781\n",
      "  Attack Epoch [1400/2000], Average Loss: 0.097711\n",
      "  Attack Epoch [1450/2000], Average Loss: 0.097785\n",
      "  Attack Epoch [1500/2000], Average Loss: 0.097784\n",
      "  Attack Epoch [1550/2000], Average Loss: 0.097770\n",
      "  Attack Epoch [1600/2000], Average Loss: 0.097746\n",
      "  Attack Epoch [1650/2000], Average Loss: 0.097776\n",
      "  Attack Epoch [1700/2000], Average Loss: 0.097666\n",
      "  Attack Epoch [1750/2000], Average Loss: 0.097667\n",
      "  Attack Epoch [1800/2000], Average Loss: 0.097699\n",
      "  Attack Epoch [1850/2000], Average Loss: 0.097602\n",
      "  Attack Epoch [1900/2000], Average Loss: 0.097658\n",
      "  Attack Epoch [1950/2000], Average Loss: 0.097658\n",
      "  Attack Epoch [2000/2000], Average Loss: 0.097656\n",
      "  Final Attack Model Average Loss: 0.097656\n",
      "\n",
      "Training attack model for: one_hot\n",
      "  Training with 1000 samples...\n",
      " Training Attack Model (2000 epochs, lr=5e-05)...\n",
      "  Attack Epoch [50/2000], Average Loss: 0.153415\n",
      "  Attack Epoch [100/2000], Average Loss: 0.121267\n",
      "  Attack Epoch [150/2000], Average Loss: 0.109357\n",
      "  Attack Epoch [200/2000], Average Loss: 0.103960\n",
      "  Attack Epoch [250/2000], Average Loss: 0.101004\n",
      "  Attack Epoch [300/2000], Average Loss: 0.099667\n",
      "  Attack Epoch [350/2000], Average Loss: 0.098951\n",
      "  Attack Epoch [400/2000], Average Loss: 0.098781\n",
      "  Attack Epoch [450/2000], Average Loss: 0.098549\n",
      "  Attack Epoch [500/2000], Average Loss: 0.098666\n",
      "  Attack Epoch [550/2000], Average Loss: 0.098543\n",
      "  Attack Epoch [600/2000], Average Loss: 0.098444\n",
      "  Attack Epoch [650/2000], Average Loss: 0.098316\n",
      "  Attack Epoch [700/2000], Average Loss: 0.098319\n",
      "  Attack Epoch [750/2000], Average Loss: 0.098343\n",
      "  Attack Epoch [800/2000], Average Loss: 0.098298\n",
      "  Attack Epoch [850/2000], Average Loss: 0.098314\n",
      "  Attack Epoch [900/2000], Average Loss: 0.098259\n",
      "  Attack Epoch [950/2000], Average Loss: 0.098236\n",
      "  Attack Epoch [1000/2000], Average Loss: 0.098189\n",
      "  Attack Epoch [1050/2000], Average Loss: 0.098227\n",
      "  Attack Epoch [1100/2000], Average Loss: 0.098289\n",
      "  Attack Epoch [1150/2000], Average Loss: 0.098117\n",
      "  Attack Epoch [1200/2000], Average Loss: 0.098144\n",
      "  Attack Epoch [1250/2000], Average Loss: 0.098070\n",
      "  Attack Epoch [1300/2000], Average Loss: 0.098084\n",
      "  Attack Epoch [1350/2000], Average Loss: 0.098141\n",
      "  Attack Epoch [1400/2000], Average Loss: 0.098130\n",
      "  Attack Epoch [1450/2000], Average Loss: 0.098063\n",
      "  Attack Epoch [1500/2000], Average Loss: 0.098113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attack Epoch [1550/2000], Average Loss: 0.098107\n",
      "  Attack Epoch [1600/2000], Average Loss: 0.098074\n",
      "  Attack Epoch [1650/2000], Average Loss: 0.098171\n",
      "  Attack Epoch [1700/2000], Average Loss: 0.098049\n",
      "  Attack Epoch [1750/2000], Average Loss: 0.098135\n",
      "  Attack Epoch [1800/2000], Average Loss: 0.098018\n",
      "  Attack Epoch [1850/2000], Average Loss: 0.098074\n",
      "  Attack Epoch [1900/2000], Average Loss: 0.098058\n",
      "  Attack Epoch [1950/2000], Average Loss: 0.098114\n",
      "  Attack Epoch [2000/2000], Average Loss: 0.098063\n",
      "  Final Attack Model Average Loss: 0.098063\n",
      "\n",
      "Attack model training finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Thay thế nội dung Cell 12 ---\n",
    "from phase2_train_attack_model import train_attack_model # Import hàm train mới\n",
    "\n",
    "attack_models = {}\n",
    "methods = [\"label_only\", \"vector_based\", \"score_based\", \"one_hot\"]\n",
    "epochs_attack = 2000 # Giữ nguyên số epochs hoặc điều chỉnh\n",
    "\n",
    "attack_lr = 5e-5   # THỬ GIÁ TRỊ THẤP HƠN   # Learning rate cho attack model mới\n",
    "attack_batch_size = 32 # Batch size cho attack model training\n",
    "\n",
    "# Device để train attack model\n",
    "device_train_attack = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Training Attack Models on {device_train_attack}...\")\n",
    "\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"\\nTraining attack model for: {method}\")\n",
    "    # Lấy dữ liệu huấn luyện đã tạo ở cell trên\n",
    "    vecs = attack_train_data[method][\"vectors\"]\n",
    "    imgs_target = attack_train_data[method][\"images\"]\n",
    "\n",
    "    if len(vecs) == 0:\n",
    "        print(f\"  Skipping {method} due to no training data.\")\n",
    "        attack_models[method] = None\n",
    "        continue\n",
    "\n",
    "    print(f\"  Training with {len(vecs)} samples...\")\n",
    "    # Huấn luyện attack model (sử dụng hàm train_attack_model đã sửa với kiến trúc mới)\n",
    "    attack_models[method] = train_attack_model(\n",
    "        vecs,\n",
    "        imgs_target,\n",
    "        epochs=epochs_attack,\n",
    "        batch_size=attack_batch_size,\n",
    "        lr=attack_lr,\n",
    "        device=device_train_attack\n",
    "    ) # Hàm này trả về model trên CPU\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"\\nAttack model training finished.\")\n",
    "# --- Kết thúc thay thế Cell 12 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1dac89",
   "metadata": {},
   "source": [
    "## Step 7: Reconstruct and Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8dea5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import phase3_reconstruct\n",
    "importlib.reload(phase3_reconstruct)\n",
    "\n",
    "from phase3_reconstruct import reconstruct_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a5dfee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from \"D:\\\\Computer Science\\\\ELTE's MSc\\\\Data Security\\\\model_inversion_mnist - Copy - Good lastesr version\\\\model_inversion_mnist\\\\utils.py\">"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f3a6659",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_test_cpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Sửa lại phần tạo dictionary `results` trong Cell 15 ---\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# method_labels đã được định nghĩa ở đầu cell:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# methods = list(method_labels.keys())\u001b[39;00m\n\u001b[0;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;66;03m# Khởi tạo results rỗng\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m ground_truth_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mimages_test_cpu\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;66;03m# Ảnh gốc để vẽ\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReconstructing test images...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images_test_cpu' is not defined"
     ]
    }
   ],
   "source": [
    "# --- CELL 15: Tái Tạo Ảnh Test và Vẽ Biểu Đồ ---\n",
    "\n",
    "# Import các thư viện và hàm cần thiết cho cell này\n",
    "import torch\n",
    "from phase3_reconstruct import reconstruct_images\n",
    "from utils import plot_comparison # Hàm vẽ biểu đồ từ utils.py\n",
    "from attacks.label_only_attack import recover_confidence_vector # Hàm khôi phục vector label-only\n",
    "# import matplotlib.pyplot as plt # Không cần import lại nếu đã import ở đầu notebook\n",
    "\n",
    "# --- Phần Khởi tạo và Lấy Dữ liệu ---\n",
    "\n",
    "# Định nghĩa nhãn cho các hàng trên biểu đồ\n",
    "method_labels = {\n",
    "    \"label_only\": \"Label only\",\n",
    "    \"vector_based\": \"Vector-based\",\n",
    "    \"score_based\": \"Score-based\",\n",
    "    \"one_hot\": \"One hot\"\n",
    "}\n",
    "# Lấy danh sách các phương thức (đảm bảo thứ tự nhất quán với các cell trước)\n",
    "methods = list(method_labels.keys())\n",
    "\n",
    "# Khởi tạo dictionary để lưu kết quả tái tạo\n",
    "results = {}\n",
    "\n",
    "# !!! SỬA LỖI NameError Ở ĐÂY !!!\n",
    "# Lấy 10 ảnh/nhãn test gốc (biến `images`, `labels` phải được định nghĩa ở Cell 10)\n",
    "# Chuyển chúng về CPU và tạo bản sao làm ground truth cho biểu đồ\n",
    "try:\n",
    "    images_test_cpu = images.cpu()  # Định nghĩa images_test_cpu\n",
    "    labels_test_cpu = labels.cpu()  # Định nghĩa labels_test_cpu\n",
    "    ground_truth_imgs = images_test_cpu.detach().clone() # Định nghĩa ground_truth_imgs\n",
    "except NameError:\n",
    "    print(\"LỖI: Biến 'images' hoặc 'labels' (10 ảnh/nhãn test) chưa được định nghĩa.\")\n",
    "    print(\"Hãy đảm bảo bạn đã chạy thành công Cell 10.\")\n",
    "    # Gán giá trị tạm để tránh lỗi tiếp theo, nhưng biểu đồ sẽ không đúng\n",
    "    ground_truth_imgs = None\n",
    "    images_test_cpu = torch.zeros(10, 1, 28, 28) # Giá trị tạm\n",
    "    labels_test_cpu = torch.zeros(10, dtype=torch.long) # Giá trị tạm\n",
    "\n",
    "# Cài đặt device và models (đảm bảo chúng đã được huấn luyện/chuẩn bị ở các cell trước)\n",
    "device_reconstruct = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "try:\n",
    "    target_model.to(device_reconstruct).eval()\n",
    "    # shadow_model nên ở trên CPU theo hàm recover_confidence_vector\n",
    "    shadow_model.cpu().eval()\n",
    "except NameError:\n",
    "    print(\"LỖI: `target_model` hoặc `shadow_model` chưa được định nghĩa/huấn luyện.\")\n",
    "    # Xử lý lỗi hoặc thoát\n",
    "\n",
    "# Lấy mu, sigma từ Cell 11 (cần cho 'label_only')\n",
    "try:\n",
    "    # Giả sử biến mu và sigma tồn tại từ Cell 11\n",
    "    mu_for_recon = mu\n",
    "    sigma_for_recon = sigma\n",
    "    print(f\"Sử dụng mu={mu_for_recon:.4f}, sigma={sigma_for_recon} để tái tạo label_only.\")\n",
    "except NameError:\n",
    "     print(\"LỖI: Biến `mu` và `sigma` không tìm thấy từ Cell 11. Không thể tái tạo cho label_only.\")\n",
    "     mu_for_recon = 0.5 # Gán giá trị tạm để tránh lỗi, nhưng kết quả label_only sẽ sai\n",
    "     sigma_for_recon = 0.1\n",
    "\n",
    "# --- Phần Tái Tạo Ảnh ---\n",
    "print(\"\\nĐang tái tạo ảnh thử nghiệm...\")\n",
    "\n",
    "# Lặp qua từng phương pháp tấn công\n",
    "for method in methods:\n",
    "    print(f\" Đang tái tạo cho: {method}\")\n",
    "\n",
    "    # Lấy attack model đã huấn luyện tương ứng (từ Cell 12)\n",
    "    # attack_models là dictionary chứa các model đã train\n",
    "    attack_model_method = attack_models.get(method)\n",
    "\n",
    "    # Kiểm tra xem model có tồn tại không (trường hợp huấn luyện lỗi)\n",
    "    if attack_model_method is None:\n",
    "        print(f\"  Bỏ qua {method} vì attack model chưa được huấn luyện.\")\n",
    "        label_name = method_labels[method] # Lấy nhãn đúng\n",
    "        # Tạo ảnh đen hoặc placeholder nếu model không có\n",
    "        results[label_name] = torch.zeros_like(images_test_cpu)\n",
    "        continue\n",
    "\n",
    "    # Chuyển model sang device và chế độ eval\n",
    "    attack_model_method = attack_model_method.to(device_reconstruct).eval()\n",
    "    vectors_to_reconstruct_list = [] # List để lưu vector của 10 ảnh test\n",
    "\n",
    "    # Tạo vector tin cậy cho từng ảnh test theo phương pháp 'method'\n",
    "    with torch.no_grad(): # Không cần tính gradient ở bước này\n",
    "        for i in range(len(images_test_cpu)): # Lặp qua 10 ảnh test\n",
    "            img_test_device = images_test_cpu[i].unsqueeze(0).to(device_reconstruct) # Thêm batch dim=1 và chuyển sang device\n",
    "            label_test = labels_test_cpu[i].item() # Lấy nhãn dạng số nguyên\n",
    "\n",
    "            # Tạo vector test dựa trên phương pháp\n",
    "            if method == \"label_only\":\n",
    "                 vec_test = recover_confidence_vector(\n",
    "                     shadow_model, mu_for_recon, label_test,\n",
    "                     num_classes=10, sigma=sigma_for_recon\n",
    "                 ) # Hàm này trả về CPU\n",
    "            elif method == \"vector_based\":\n",
    "                 vec_test = torch.softmax(target_model(img_test_device), dim=1).squeeze().cpu()\n",
    "            elif method == \"score_based\":\n",
    "                 prob_sb = torch.softmax(target_model(img_test_device), dim=1).squeeze().cpu()\n",
    "                 max_idx_sb = torch.argmax(prob_sb)\n",
    "                 vec_test = torch.zeros_like(prob_sb)\n",
    "                 if 0 <= max_idx_sb < len(vec_test):\n",
    "                     vec_test[max_idx_sb] = prob_sb[max_idx_sb]\n",
    "                 else: # Xử lý trường hợp index lỗi (dù hiếm)\n",
    "                      vec_test[0] = 1.0 # Hoặc xử lý khác\n",
    "            elif method == \"one_hot\":\n",
    "                 pred_oh = torch.argmax(target_model(img_test_device), dim=1).item()\n",
    "                 vec_test = torch.zeros(10) # Kích thước num_classes\n",
    "                 if 0 <= pred_oh < 10: # Kiểm tra index hợp lệ\n",
    "                     vec_test[pred_oh] = 1.0\n",
    "                 else: # Xử lý trường hợp index lỗi\n",
    "                      vec_test[0] = 1.0 # Hoặc xử lý khác\n",
    "\n",
    "            vectors_to_reconstruct_list.append(vec_test.cpu()) # Đảm bảo mọi vector đều ở CPU\n",
    "\n",
    "    # Ghép các vector thành một batch và chuyển sang device để tái tạo\n",
    "    vecs_to_reconstruct = torch.stack(vectors_to_reconstruct_list).to(device_reconstruct)\n",
    "\n",
    "    # Tái tạo ảnh bằng attack model tương ứng\n",
    "    with torch.no_grad():\n",
    "        recon = reconstruct_images(attack_model_method, vecs_to_reconstruct)\n",
    "\n",
    "    # Lưu kết quả vào dictionary với nhãn ngắn gọn làm key\n",
    "    label_name = method_labels[method]\n",
    "    results[label_name] = recon.cpu().detach() # Chuyển kết quả về CPU và detach khỏi graph\n",
    "\n",
    "# --- Phần Vẽ Biểu Đồ ---\n",
    "print(\"\\nĐang vẽ biểu đồ so sánh...\")\n",
    "\n",
    "if ground_truth_imgs is not None:\n",
    "    # Kiểm tra xem có đủ kết quả cho các phương pháp không\n",
    "     if len(results) == len(methods):\n",
    "         plot_comparison(ground_truth_imgs, results, title='Model Inversion Comparison')\n",
    "     else:\n",
    "          # In cảnh báo nếu số lượng kết quả không khớp số phương pháp\n",
    "          print(f\"Warning: Number of results ({len(results)}) does not match number of methods ({len(methods)}). Plot might be incomplete.\")\n",
    "          # Vẫn vẽ với những gì có được\n",
    "          plot_comparison(ground_truth_imgs, results, title='Model Inversion Comparison (Incomplete)')\n",
    "\n",
    "else:\n",
    "    print(\"Không thể lấy ảnh gốc để vẽ biểu đồ.\")\n",
    "\n",
    "# --- Kết thúc Cell 15 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29daccb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (with torch)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
