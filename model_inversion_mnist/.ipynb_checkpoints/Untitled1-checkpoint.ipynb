{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "nb = nbformat.v4.new_notebook()\n",
    "nb.metadata.kernelspec = {\n",
    "    \"display_name\": \"Python (with torch)\",\n",
    "    \"language\": \"python\",\n",
    "    \"name\": \"torch_env\"\n",
    "}\n",
    "nb.cells = [\n",
    "    nbformat.v4.new_markdown_cell(\"# Model Inversion on MNIST using Label-only Attack\\n\\n\"\n",
    "        \"This notebook demonstrates how to reconstruct MNIST images using four types of model inversion attacks:\\n\"\n",
    "        \"- **Label-only**\\n\"\n",
    "        \"- **Vector-based**\\n\"\n",
    "        \"- **Score-based**\\n\"\n",
    "        \"- **One-hot**\\n\\n\"\n",
    "        \"We follow the steps from the paper *Label-only Model Inversion Attack: The Attack that Requires the Least*.\"\n",
    "    ),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 1: Install Dependencies\\n\"\n",
    "        \"Run this cell once to install required packages.\"\n",
    "    ),\n",
    "    nbformat.v4.new_code_cell(\"\"\"!pip install torch torchvision matplotlib scipy tqdm ipykernel\"\"\"),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 2: Setup Kernel and Imports\"),\n",
    "    nbformat.v4.new_code_cell(\"\"\"import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Project modules\n",
    "from data_loader import load_mnist_data\n",
    "from utils import add_gaussian_noise, compute_error_rate, compute_mse, plot_comparison\n",
    "from phase1_vector_recovery import generate_confidence_vectors\n",
    "from phase2_train_attack_model import train_attack_model\n",
    "from phase3_reconstruct import reconstruct_images\n",
    "from phase4_evaluation import evaluate_reconstructions\n",
    "\n",
    "# Attack-specific imports\n",
    "from attacks.label_only_attack import train_shadow_model, recover_confidence_vector\n",
    "from attacks.vector_based_attack import get_confidence_vector\n",
    "from attacks.score_based_attack import get_score_based_vector\n",
    "from attacks.one_hot_attack import get_one_hot_vector\n",
    "\n",
    "print(\"Imports successful.\")\"\"\"),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 3: Load MNIST Dataset\"),\n",
    "    nbformat.v4.new_code_cell(\"\"\"# Load MNIST\n",
    "train_set, test_set = load_mnist_data()\n",
    "print(f\"Train samples: {len(train_set)}, Test samples: {len(test_set)}\")\"\"\"),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 4: Prepare Data Loaders and Sets\"),\n",
    "    nbformat.v4.new_code_cell(\"\"\"# Define auxiliary fraction\n",
    "aux_frac = 0.02\n",
    "n_aux = int(len(train_set) * aux_frac)\n",
    "aux_indices = list(range(n_aux))\n",
    "aux_set = Subset(train_set, aux_indices)\n",
    "rest_indices = list(range(n_aux, len(train_set)))\n",
    "rest_set = Subset(train_set, rest_indices)\n",
    "\n",
    "batch_size = 128\n",
    "loader_rest = DataLoader(rest_set, batch_size=batch_size, shuffle=True)\n",
    "loader_aux = DataLoader(aux_set, batch_size=n_aux, shuffle=False)\n",
    "loader_test = DataLoader(test_set, batch_size=10000, shuffle=False)\n",
    "\n",
    "print(f\"Aux set size = {len(aux_set)}, Rest set size = {len(rest_set)}\")\"\"\"),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 5: Define and Train Target CNN\"),\n",
    "    nbformat.v4.new_code_cell(\"\"\"# Target CNN architecture\n",
    "class TargetCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1,32,3,padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*3*3,256), nn.ReLU(),\n",
    "            nn.Linear(256,num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "target_model = TargetCNN().to(device)\n",
    "\n",
    "# Train target model\n",
    "optimizer = optim.Adam(target_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    target_model.train()\n",
    "    total_loss = 0.0\n",
    "    for imgs, labels in loader_rest:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = target_model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()*imgs.size(0)\n",
    "    print(f\"Epoch {epoch+1}, loss = {total_loss/len(rest_set):.4f}\")\"\"\"),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 6: Train Shadow Model and Compute mu\"),\n",
    "    nbformat.v4.new_code_cell(\"\"\"# Load auxiliary data\n",
    "aux_images, aux_labels = next(iter(loader_aux))\n",
    "aux_images, aux_labels = aux_images.to(device), aux_labels.to(device)\n",
    "\n",
    "# Add noise and compute error rate mu\n",
    "sigma = 0.1\n",
    "noisy_aux = add_gaussian_noise(aux_images, sigma).to(device)\n",
    "mu = compute_error_rate(target_model, noisy_aux, aux_labels, device)\n",
    "print(f\"Computed mu = {mu:.4f}\")\n",
    "\n",
    "# Train shadow model on CPU\n",
    "shadow = train_shadow_model(aux_images.cpu(), noisy_aux.cpu())\n",
    "print(\"Shadow model trained.\")\"\"\"),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 7: Generate Confidence Vectors\"),\n",
    "    nbformat.v4.new_code_cell(\"\"\"methods = ['label_only','vector_based','score_based','one_hot']\n",
    "vectors_dict = {}\n",
    "targets_dict = {}\n",
    "\n",
    "images_cpu = aux_images.cpu()\n",
    "labels_cpu = aux_labels.cpu()\n",
    "\n",
    "for m in methods:\n",
    "    if m == 'label_only':\n",
    "        vecs, tars = generate_confidence_vectors(\n",
    "            images_cpu, labels_cpu, target_model,\n",
    "            method=m, shadow_model=shadow, mu=mu,\n",
    "            num_classes=10, sigma=sigma, device=device\n",
    "        )\n",
    "    else:\n",
    "        vecs, tars = generate_confidence_vectors(\n",
    "            images_cpu, labels_cpu, target_model,\n",
    "            method=m, num_classes=10, device=device\n",
    "        )\n",
    "    vectors_dict[m] = vecs\n",
    "    targets_dict[m] = tars\n",
    "    print(f\"{m}: vectors {vecs.shape}, targets {tars.shape}\")\"\"\"),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 8: Train Attack Models\"),\n",
    "    nbformat.v4.new_code_cell(\"\"\"attack_models = {}\n",
    "for m in methods:\n",
    "    vecs = vectors_dict[m]\n",
    "    imgs = targets_dict[m]\n",
    "    print(f\"Training {m} attack model...\")\n",
    "    attack_models[m] = train_attack_model(vecs, imgs, epochs=100)\n",
    "print(\"Attack models trained.\")\"\"\"),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 9: Reconstruct Test Images\"),\n",
    "    nbformat.v4.new_code_cell(\"\"\"# Get first 10 test samples\n",
    "test_imgs, test_lbls = next(iter(loader_test))\n",
    "test_imgs = test_imgs[:10].to(device)\n",
    "test_lbls = test_lbls[:10]\n",
    "\n",
    "recon_dict = {}\n",
    "for m in methods:\n",
    "    vecs = []\n",
    "    for i in range(10):\n",
    "        x = test_imgs[i]\n",
    "        if m == 'label_only':\n",
    "            vec = recover_confidence_vector(shadow, mu, test_lbls[i].item(),\n",
    "                                            num_classes=10, sigma=sigma)\n",
    "        elif m == 'vector_based':\n",
    "            vec = get_confidence_vector(target_model, x)\n",
    "        elif m == 'score_based':\n",
    "            vec = get_score_based_vector(target_model, x)\n",
    "        else:\n",
    "            vec = get_one_hot_vector(target_model, x)\n",
    "        vecs.append(vec.cpu())\n",
    "    vecs = torch.stack(vecs)\n",
    "    recon = reconstruct_images(attack_models[m], vecs.to(device))\n",
    "    recon_dict[m] = recon.cpu()\n",
    "print(\"Reconstruction complete.\")\"\"\"),\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 10: Evaluate and Plot\"),\n",
    "    nbformat.v4.new_code_cell(\"\"\"# Ground truth for first 10\n",
    "ground = test_imgs.cpu()\n",
    "\n",
    "labels_map = {\n",
    "    'label_only': 'Label-only',\n",
    "    'vector_based': 'Vector-based',\n",
    "    'score_based': 'Score-based',\n",
    "    'one_hot': 'One-hot'\n",
    "}\n",
    "plot_dict = {labels_map[m]: recon_dict[m] for m in methods}\n",
    "\n",
    "plot_comparison(ground, plot_dict, title='Inversion Comparison')\"\"\")\n",
    "]\n",
    "\n",
    "path = '/mnt/data/model_inversion_mnist_fixed.ipynb'\n",
    "with open(path, 'w') as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (with torch)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
